{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/emanafi/research-assistant-agent?scriptVersionId=283204052\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"id":"c0d66ec6","cell_type":"markdown","source":"# Capstone Project: Advanced Research Assistant Agent\n\n**Track:** Freestyle / Agents for Good (Education/Research)\n\n**Objective:** Build a comprehensive AI agent system that helps researchers by:\n1.  Searching for papers on multiple sub-topics in **parallel**.\n2.  **Analyzing** the findings (e.g., plotting publication trends) using code execution.\n3.  **Formatting** citations.\n4.  **Saving** interesting findings to a persistent \"Long-Term Memory\".\n\n**Key Concepts Applied:**\n\n1.  **Multi-agent system**:\n    *   **Parallel agents**: We implement a `parallel_research` tool that spawns multiple search tasks simultaneously.\n    *   **Sequential agents**: The workflow moves from Research -> Analysis -> Formatting.\n    *   **Agent powered by an LLM**: All agents use Gemini.\n\n2.  **Tools**:\n    *   **Built-in tools**: `google_search` and `code_execution`.\n    *   **Custom tools**: `format_citation`, `save_to_memory`, `parallel_research`.\n\n3.  **Sessions & Memory**:\n    *   **Sessions**: `InMemorySessionService` for conversation context.\n    *   **Long-term memory**: A file-based JSON store (`knowledge_base.json`) to persist data across sessions.\n\n4.  **Observability**:\n    *   **Logging**: Detailed logging of tool usage and agent steps.\n\n5.  **Agent evaluation**:\n    *   Automated checks for output quality.\n\n6.  **Agent deployment**:\n    *   **Deployment**: We demonstrate how to wrap the agent in a Vertex AI Agent Engine & a Flask API for deployment as a web service.","metadata":{}},{"id":"5485ddb6","cell_type":"markdown","source":"## ‚öôÔ∏è 1. Setup and Configuration\n\nFirst, we install the necessary dependencies and configure the API key.\n\n### 1.1: Install ADK","metadata":{}},{"id":"c33de000","cell_type":"code","source":"# Install the Agent Development Kit (ADK), ArXiv and AsyncIO\n!pip install google-adk arxiv nest-asyncio\n\nprint(\"‚úÖ ADK, ArXiv, and nest-asyncio installed successfully.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:58:32.253375Z","iopub.execute_input":"2025-11-30T21:58:32.253715Z","iopub.status.idle":"2025-11-30T21:58:43.369598Z","shell.execute_reply.started":"2025-11-30T21:58:32.253689Z","shell.execute_reply":"2025-11-30T21:58:43.368636Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-adk in /usr/local/lib/python3.11/dist-packages (1.18.0)\nCollecting arxiv\n  Downloading arxiv-2.3.1-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\nRequirement already satisfied: PyYAML<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.3)\nRequirement already satisfied: anyio<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.11.0)\nRequirement already satisfied: authlib<2.0.0,>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.6.5)\nRequirement already satisfied: click<9.0.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from google-adk) (8.3.0)\nRequirement already satisfied: fastapi<1.119.0,>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.116.1)\nRequirement already satisfied: google-api-python-client<3.0.0,>=2.157.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.177.0)\nRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.125.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.125.0)\nRequirement already satisfied: google-cloud-bigtable>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-discoveryengine<0.14.0,>=0.13.12 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.13.12)\nRequirement already satisfied: google-cloud-secret-manager<3.0.0,>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.25.0)\nRequirement already satisfied: google-cloud-spanner<4.0.0,>=3.56.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.56.0)\nRequirement already satisfied: google-cloud-speech<3.0.0,>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-storage<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.5.0)\nRequirement already satisfied: google-genai<2.0.0,>=1.45.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.48.0)\nRequirement already satisfied: graphviz<1.0.0,>=0.20.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.21)\nRequirement already satisfied: mcp<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.20.0)\nRequirement already satisfied: opentelemetry-api<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-exporter-gcp-logging<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-trace<2.0.0,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.36.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-resourcedetector-gcp<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-sdk<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.12.4)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.9.0.post0)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.2.1)\nRequirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.32.5)\nRequirement already satisfied: sqlalchemy-spanner>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.17.1)\nRequirement already satisfied: sqlalchemy<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.0.41)\nRequirement already satisfied: starlette<1.0.0,>=0.46.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.47.2)\nRequirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (9.1.2)\nRequirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.15.0)\nRequirement already satisfied: tzlocal<6.0,>=5.3 in /usr/local/lib/python3.11/dist-packages (from google-adk) (5.3.1)\nRequirement already satisfied: uvicorn<1.0.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.35.0)\nRequirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.0)\nRequirement already satisfied: websockets<16.0.0,>=15.0.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (15.0.1)\nCollecting feedparser~=6.0.10 (from arxiv)\n  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (3.11)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (1.3.1)\nRequirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<2.0.0,>=1.5.1->google-adk) (46.0.3)\nCollecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.22.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.38.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.28.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.2.0)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (6.33.0)\nRequirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (25.0)\nRequirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.35.1)\nRequirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.14.2)\nRequirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.1.2)\nRequirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.17.0)\nRequirement already satisfied: cloudpickle<4.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.1.2)\nRequirement already satisfied: google-cloud-trace<2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.17.0)\nRequirement already satisfied: google-cloud-logging<4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.12.1)\nRequirement already satisfied: google-cloud-core<3.0.0,>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (2.4.3)\nRequirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (0.14.2)\nRequirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (1.7.1)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-secret-manager<3.0.0,>=2.22.0->google-adk) (1.74.0)\nRequirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.5.3)\nRequirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.15.4)\nRequirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<4.0.0,>=3.0.0->google-adk) (2.7.2)\nRequirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.45.0->google-adk) (0.28.1)\nRequirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.4.3)\nRequirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (4.25.0)\nRequirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (2.11.0)\nRequirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.8.0->google-adk) (2.10.1)\nRequirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.0.20)\nRequirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (3.0.3)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (8.7.0)\nRequirement already satisfied: google-cloud-monitoring~=2.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0->google-adk) (2.28.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.70.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<=1.37.0,>=1.37.0->google-adk) (0.58b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.4.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.9.0.post0->google-adk) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2025.10.5)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0->google-adk) (3.2.3)\nRequirement already satisfied: alembic in /usr/local/lib/python3.11/dist-packages (from sqlalchemy-spanner>=1.14.0->google-adk) (1.17.1)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1.0.0,>=0.34.0->google-adk) (0.16.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.71.2)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk)\n  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.9.1)\nRequirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.7.0)\nRequirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.4.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (3.0.9)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.45.0->google-adk) (1.0.9)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (3.23.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.26.0)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.0.0)\nRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.4)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic->sqlalchemy-spanner>=1.14.0->google-adk) (1.3.10)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=2.0.0->cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.23)\nCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.4.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.6.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic->sqlalchemy-spanner>=1.14.0->google-adk) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nDownloading arxiv-2.3.1-py3-none-any.whl (11 kB)\nDownloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=f85aa0805cf84941a03bb33291259dd0884b53b06e83acec0f9388bcf1329856\n  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\nSuccessfully built sgmllib3k\nInstalling collected packages: sgmllib3k, protobuf, feedparser, cachetools, arxiv\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 6.2.1\n    Uninstalling cachetools-6.2.1:\n      Successfully uninstalled cachetools-6.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed arxiv-2.3.1 cachetools-5.5.2 feedparser-6.0.12 protobuf-5.29.5 sgmllib3k-1.0.0\n‚úÖ ADK, ArXiv, and nest-asyncio installed successfully.\n","output_type":"stream"}],"execution_count":1},{"id":"05920197","cell_type":"markdown","source":"### 1.2: Configure API Key","metadata":{}},{"id":"d8bef717","cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:58:47.332035Z","iopub.execute_input":"2025-11-30T21:58:47.332378Z","iopub.status.idle":"2025-11-30T21:58:47.501263Z","shell.execute_reply.started":"2025-11-30T21:58:47.332349Z","shell.execute_reply":"2025-11-30T21:58:47.500271Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"id":"ab9bac38","cell_type":"markdown","source":"### 1.3: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"id":"fd7e8b96","cell_type":"code","source":"from google.genai import types\n\nretry_config = types.HttpRetryOptions(\n    attempts=3,\n    exp_base=2,\n    initial_delay=1,\n    http_status_codes=[429, 500, 503],\n)\n\nprint(\"‚úÖ Retry configuration set.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:58:50.036159Z","iopub.execute_input":"2025-11-30T21:58:50.036473Z","iopub.status.idle":"2025-11-30T21:58:54.430865Z","shell.execute_reply.started":"2025-11-30T21:58:50.036448Z","shell.execute_reply":"2025-11-30T21:58:54.429849Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Retry configuration set.\n","output_type":"stream"}],"execution_count":3},{"id":"47af0f33","cell_type":"markdown","source":"## üõ†Ô∏è 2. Define Tools (Built-in & Custom)\n\nWe define a set of tools to empower our agents:\n1.  **`format_citation`**: Formats paper details.\n2.  **`save_to_memory`**: Persists data to a JSON file (Long-Term Memory).\n3.  **`parallel_research`**: Simulates parallel agent execution for broader search coverage.\n\n### 2.1: Import ADK Components","metadata":{}},{"id":"75df760f","cell_type":"code","source":"import json\nimport logging\nimport asyncio\nfrom typing import List, Dict, Any\nfrom google.genai.types import Content, Part\n\n# ADK Imports\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import google_search, AgentTool\nfrom google.adk.code_executors import BuiltInCodeExecutor\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:58:59.657307Z","iopub.execute_input":"2025-11-30T21:58:59.658295Z","iopub.status.idle":"2025-11-30T21:59:44.424274Z","shell.execute_reply.started":"2025-11-30T21:58:59.65826Z","shell.execute_reply":"2025-11-30T21:59:44.423244Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":4},{"id":"b7c39ee0","cell_type":"markdown","source":"### 2.2: Configure Logging for Observability\n\nSet up logging to track agent operations and tool usage throughout the application.","metadata":{}},{"id":"85ca2e8d","cell_type":"code","source":"# Configure Logging for Observability\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\nprint(\"‚úÖ Logging configured.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:59:49.872732Z","iopub.execute_input":"2025-11-30T21:59:49.874034Z","iopub.status.idle":"2025-11-30T21:59:49.880151Z","shell.execute_reply.started":"2025-11-30T21:59:49.873992Z","shell.execute_reply":"2025-11-30T21:59:49.879293Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Logging configured.\n","output_type":"stream"}],"execution_count":5},{"id":"e9f74332","cell_type":"markdown","source":"### 2.3: Helper Functions for ADK Web UI\n\nHelper functions for accessing the ADK web interface in the Kaggle Notebooks environment.","metadata":{}},{"id":"80c28d63","cell_type":"code","source":"from IPython.core.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n# Gets the proxied URL in the Kaggle Notebooks environment\ndef get_adk_proxy_url():\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0]['base_url']\n\n    try:\n        path_parts = baseURL.split('/')\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n            </ol>\n            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after running cell below) ‚Üó\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n\n    return url_prefix\n\nprint(\"‚úÖ Helper functions defined.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:59:52.337179Z","iopub.execute_input":"2025-11-30T21:59:52.337534Z","iopub.status.idle":"2025-11-30T21:59:52.518253Z","shell.execute_reply.started":"2025-11-30T21:59:52.337483Z","shell.execute_reply":"2025-11-30T21:59:52.517362Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Helper functions defined.\n","output_type":"stream"}],"execution_count":6},{"id":"e3a09e84","cell_type":"markdown","source":"### 2.4: Define Custom Tools","metadata":{}},{"id":"d5ee3c7a","cell_type":"code","source":"import arxiv\nimport time\n\n# --- ArXiv API Tool ---\ndef search_arxiv(query: str, max_results: int = 5) -> str:\n    \"\"\"\n    Searches ArXiv for research papers matching the query.\n    Includes retry logic and uses the updated Client API to avoid deprecation warnings.\n    \n    Args:\n        query: Search query for papers\n        max_results: Maximum number of results to return (default: 5)\n        \n    Returns:\n        Formatted string with paper details\n    \"\"\"\n    client = arxiv.Client()\n    \n    search = arxiv.Search(\n        query=query,\n        max_results=max_results,\n        sort_by=arxiv.SortCriterion.SubmittedDate\n    )\n    \n    results = []\n    try:\n        # Use client.results() instead of search.results() to fix deprecation warning\n        # and add retry logic for robustness\n        for attempt in range(3):\n            try:\n                # Convert generator to list to ensure we actually fetch data\n                found_papers = list(client.results(search))\n                break\n            except Exception as e:\n                if attempt == 2: # Last attempt\n                    raise e\n                time.sleep(1) # Wait 1s before retry\n        \n        for paper in found_papers:\n            result = {\n                \"title\": paper.title,\n                \"authors\": [author.name for author in paper.authors],\n                \"summary\": paper.summary[:300] + \"...\" if len(paper.summary) > 300 else paper.summary,\n                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n                \"url\": paper.entry_id,\n                \"pdf_url\": paper.pdf_url\n            }\n            results.append(result)\n            \n        if not results:\n            return f\"No papers found for query: {query}\"\n            \n        # Format results\n        formatted = f\"Found {len(results)} papers for '{query}':\\n\\n\"\n        for i, paper in enumerate(results, 1):\n            authors = \", \".join(paper[\"authors\"][:3])\n            if len(paper[\"authors\"]) > 3:\n                authors += \" et al.\"\n            formatted += f\"{i}. **{paper['title']}**\\n\"\n            formatted += f\"   Authors: {authors}\\n\"\n            formatted += f\"   Published: {paper['published']}\\n\"\n            formatted += f\"   URL: {paper['url']}\\n\"\n            formatted += f\"   Summary: {paper['summary']}\\n\\n\"\n            \n        logger.info(f\"ArXiv search completed: {len(results)} results for '{query}'\")\n        return formatted\n        \n    except Exception as e:\n        error_msg = f\"ArXiv search failed: {str(e)}\"\n        logger.error(error_msg)\n        return f\"Error searching ArXiv: {str(e)}\"\n\nprint(\"‚úÖ ArXiv search tool defined (updated with Client API and retries).\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:59:55.811834Z","iopub.execute_input":"2025-11-30T21:59:55.812451Z","iopub.status.idle":"2025-11-30T21:59:55.863094Z","shell.execute_reply.started":"2025-11-30T21:59:55.812426Z","shell.execute_reply":"2025-11-30T21:59:55.862239Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ ArXiv search tool defined (updated with Client API and retries).\n","output_type":"stream"}],"execution_count":7},{"id":"1253d72a","cell_type":"code","source":"# --- Custom Tool 1: Citation Formatter ---\ndef format_citation(title: str, authors: List[str], year: str, url: str) -> str:\n    \"\"\"Formats a research paper citation.\"\"\"\n    author_str = \", \".join(authors)\n    citation = f\"{author_str} ({year}). **{title}**. Retrieved from {url}\"\n    logger.info(f\"Formatted citation for: {title}\")\n    return citation\n\n# --- Custom Tool 2: Long-Term Memory (File-based) ---\nMEMORY_FILE = \"knowledge_base.json\"\n\ndef save_to_memory(key: str, value: Any) -> str:\n    \"\"\"Saves a key-value pair to a persistent JSON file.\"\"\"\n    try:\n        if os.path.exists(MEMORY_FILE):\n            with open(MEMORY_FILE, 'r') as f:\n                data = json.load(f)\n        else:\n            data = {}\n            \n        data[key] = value\n        \n        with open(MEMORY_FILE, 'w') as f:\n            json.dump(data, f, indent=2)\n            \n        logger.info(f\"Saved to memory: {key}\")\n        return f\"Successfully saved '{key}' to long-term memory.\"\n    except Exception as e:\n        return f\"Error saving to memory: {str(e)}\"\n\n# --- Custom Tool 3: Parallel Research Orchestrator ---\n# Note: In a real scenario, this would spawn independent agent processes.\n# Here, we simulate it by running multiple google searches concurrently.\n\nasync def parallel_research(topics: List[str]) -> List[str]:\n    \"\"\"\n    Performs research on multiple topics simultaneously.\n    Args:\n        topics: A list of sub-topics to research.\n    Returns:\n        A combined list of search results for all topics.\n    \"\"\"\n    logger.info(f\"Starting parallel research on: {topics}\")\n    \n    # Define a helper for a single search\n    async def search_topic(topic):\n        # We use the google_search tool directly here for simulation\n        # In a full ADK app, this could be `await researcher_agent.run(topic)`\n        logger.info(f\"Searching for: {topic}\")\n        return google_search(topic)\n\n    # Run searches in parallel\n    results = await asyncio.gather(*(search_topic(topic) for topic in topics))\n    \n    # Combine results\n    combined_results = []\n    for topic, result in zip(topics, results):\n        combined_results.append(f\"--- Results for '{topic}' ---\\n{result}\\n\")\n        \n    return combined_results\n\nprint(\"‚úÖ Custom tools defined: format_citation, save_to_memory, parallel_research.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:00:03.167842Z","iopub.execute_input":"2025-11-30T22:00:03.168227Z","iopub.status.idle":"2025-11-30T22:00:03.178427Z","shell.execute_reply.started":"2025-11-30T22:00:03.168202Z","shell.execute_reply":"2025-11-30T22:00:03.177476Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Custom tools defined: format_citation, save_to_memory, parallel_research.\n","output_type":"stream"}],"execution_count":8},{"id":"4387c480","cell_type":"markdown","source":"## ü§ñ 3. Define Agents\n\nWe define a robust multi-agent system:\n1.  **`researcher_agent`**: Uses `parallel_research` to gather broad information.\n2.  **`analyst_agent`**: Uses `BuiltInCodeExecutor` to analyze data (e.g., calculate stats, plot trends).\n3.  **`formatter_agent`**: Formats citations.\n4.  **`root_agent`**: Orchestrates the entire pipeline.","metadata":{}},{"id":"f64d0d5a","cell_type":"code","source":"# 1. Researcher Agent (Parallel Capabilities with ArXiv)\nresearcher_agent = LlmAgent(\n    name=\"researcher_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    description=\"Searches for research papers using ArXiv API.\",\n    instruction=\"\"\"\n    You are a research assistant with access to ArXiv.\n    When given a research topic:\n    1. Use the 'search_arxiv' tool to find relevant academic papers.\n    2. Focus on recent papers (2023-2025 when possible).\n    3. Return the paper details including titles, authors, dates, and URLs.\n    \"\"\",\n    tools=[search_arxiv]\n)\n\n# 2. Analyst Agent (Manual Analysis)\nanalyst_agent = LlmAgent(\n    name=\"analyst_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    description=\"Analyzes research data and creates visualizations.\",\n    instruction=\"\"\"\n    You are a data analyst.\n    Given a list of research papers or search results:\n    1. Extract the publication years from the paper information.\n    2. Calculate the distribution of papers by year.\n    3. Create a simple ASCII bar chart showing the distribution.\n    4. Return the analysis summary and the ASCII chart.\n    \n    Example ASCII chart format:\n    2025: *** (3 papers)\n    2024: ***** (5 papers)\n    2023: ** (2 papers)\n    \"\"\"\n)\n\n# 3. Formatter Agent\nformatter_agent = LlmAgent(\n    name=\"formatter_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    description=\"Formats paper details into proper citations.\",\n    instruction=\"\"\"\n    You are a citation expert. \n    Take the raw paper information and format it into clean academic citations.\n    Use APA format: Authors (Year). Title. Retrieved from URL\n    Return the final list of formatted citations as a numbered list.\n    \"\"\"\n)\n\n# 4. Root Agent (Orchestrator & Memory Manager)\nroot_agent = LlmAgent(\n    name=\"root_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    instruction=\"\"\"\n    You are the Lead Research Coordinator.\n    \n    Your workflow is:\n    1. **Research**: Delegate to 'researcher_agent' to find papers on the user's topic.\n    2. **Analyze**: Delegate the findings to 'analyst_agent' to get a distribution of publication years.\n    3. **Format**: Delegate to 'formatter_agent' to get a list of citations.\n    4. **Save**: Use the 'save_to_memory' tool to save the final citation list and analysis to the 'knowledge_base.json' file. Use the topic as the key.\n    5. **Report**: YOU MUST PRINT the final report to the user.\n       - Show the \"Formatted Citations\" list.\n       - Show the \"Publication Year Analysis\" chart.\n       - Confirm that data has been saved to memory.\n       \n    CRITICAL: Do NOT stop after calling tools. You MUST generate a final text response summarizing the results.\n    \"\"\",\n    tools=[\n        AgentTool(agent=researcher_agent), \n        AgentTool(agent=analyst_agent), \n        AgentTool(agent=formatter_agent),\n        save_to_memory\n    ]\n)\n\nprint(\"‚úÖ Agents defined: Researcher, Analyst, Formatter, and Root.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:00:07.848254Z","iopub.execute_input":"2025-11-30T22:00:07.84914Z","iopub.status.idle":"2025-11-30T22:00:07.857842Z","shell.execute_reply.started":"2025-11-30T22:00:07.849106Z","shell.execute_reply":"2025-11-30T22:00:07.856826Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Agents defined: Researcher, Analyst, Formatter, and Root.\n","output_type":"stream"}],"execution_count":9},{"id":"a1506b0e","cell_type":"markdown","source":"## ‚öñÔ∏è 4. Evaluation Logic\n\nWe define an evaluation function to check if the agent's response meets our requirements (contains a list, recent years, and URLs). We will use this during the agent execution.","metadata":{}},{"id":"afc5b990","cell_type":"code","source":"def evaluate_response(response_text: str):\n    \"\"\"\n    Evaluation to check if the response contains citations, analysis, and confirms saving.\n    \"\"\"\n    score = 0\n    checks = []\n    \n    # Check 1: List format (Citations)\n    if \"1.\" in response_text or \"-\" in response_text:\n        score += 1\n        checks.append(\"List format detected\")\n    \n    # Check 2: Recent years\n    if \"2024\" in response_text or \"2025\" in response_text:\n        score += 1\n        checks.append(\"Recent years detected\")\n        \n    # Check 3: URLs\n    if \"http\" in response_text:\n        score += 1\n        checks.append(\"URLs detected\")\n\n    # Check 4: Analysis/Chart\n    if \"Analysis\" in response_text or \"|\" in response_text or \"*\" in response_text: # Simple check for ASCII chart chars\n        score += 1\n        checks.append(\"Analysis/Chart detected\")\n\n    # Check 5: Memory Save\n    if \"saved\" in response_text.lower() or \"memory\" in response_text.lower():\n        score += 1\n        checks.append(\"Memory save confirmed\")\n        \n    print(f\"\\n--- Evaluation Results ---\")\n    print(f\"Score: {score}/5\")\n    print(f\"Checks passed: {', '.join(checks)}\")\n    \nprint(\"‚úÖ Evaluation function defined.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:00:13.609412Z","iopub.execute_input":"2025-11-30T22:00:13.610119Z","iopub.status.idle":"2025-11-30T22:00:13.617354Z","shell.execute_reply.started":"2025-11-30T22:00:13.610092Z","shell.execute_reply":"2025-11-30T22:00:13.616343Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Evaluation function defined.\n","output_type":"stream"}],"execution_count":10},{"id":"e0796cf0","cell_type":"markdown","source":"## ‚ñ∂Ô∏è 5. Run the Agent\n\nNow we can interact with our agent. The `run_agent` function handles session management automatically, creating a fresh session for each query to ensure reliability in notebook environments.","metadata":{}},{"id":"db0bdcc5","cell_type":"code","source":"# Initialize Session Service and Runner\nfrom google.adk.runners import Runner\nimport nest_asyncio\nimport traceback\nimport logging\n\n# Apply nest_asyncio to allow nested event loops (critical for notebook environments)\nnest_asyncio.apply()\n\n# Suppress the specific google_genai warning about non-text parts\nlogging.getLogger(\"google_genai.types\").setLevel(logging.ERROR)\n\nAPP_NAME = \"research_agent\"\nUSER_ID = \"researcher_01\"\n\nsession_service = InMemorySessionService()\nrunner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n\nprint(\"‚úÖ Session service and runner initialized.\")\nprint(f\"   - Application: {APP_NAME}\")\nprint(f\"   - User: {USER_ID}\")\nprint(f\"   - Using: {session_service.__class__.__name__}\")\n\nasync def run_agent(query: str, session_id: str = \"default_session\"):\n    \"\"\"\n    Runs the agent with the given query and returns the full response.\n    Includes debug logging to trace execution flow and errors.\n    \"\"\"\n    print(f\"User > {query}\")\n    print(\"-\" * 50)\n    \n    # Create or get the session\n    try:\n        session = await session_service.create_session(\n            app_name=APP_NAME, \n            user_id=USER_ID, \n            session_id=session_id\n        )\n    except:\n        session = await session_service.get_session(\n            app_name=APP_NAME, \n            user_id=USER_ID, \n            session_id=session_id\n        )\n    \n    full_response = \"\"\n    \n    # Create a Content object from the query string\n    message = Content(parts=[Part(text=query)], role=\"user\")\n    \n    event_count = 0\n    try:\n        # Run the agent asynchronously with the session\n        async for event in runner.run_async(\n            user_id=USER_ID, \n            session_id=session.id,\n            new_message=message\n        ):\n            event_count += 1\n            \n            # Check for content parts\n            if event.content and event.content.parts:\n                for part in event.content.parts:\n                    # Handle text parts\n                    if part.text and part.text != \"None\":\n                        print(f\"Agent > {part.text}\")\n                        full_response += part.text + \"\\n\"\n                    \n                    # Handle function calls\n                    if part.function_call:\n                        print(f\"ü§ñ Agent is calling tool: {part.function_call.name}\")\n            \n            # Log errors if present in the event\n            if hasattr(event, 'error') and event.error:\n                print(f\"‚ö†Ô∏è Event Error: {event.error}\")\n                \n    except Exception as e:\n        print(f\"‚ùå Error during agent execution: {str(e)}\")\n        traceback.print_exc()\n        \n    if event_count == 0:\n        print(\"‚ö†Ô∏è Warning: No events received from the agent. Check network connection and API keys.\")\n    elif not full_response.strip():\n        print(\"‚ö†Ô∏è Warning: Agent executed tools but returned no final text response.\")\n        print(\"   This usually means the agent loop finished before the final answer was generated.\")\n        print(\"   Try running the cell again, or check if the 'Root Agent' instructions are clear.\")\n                \n    return full_response\n\n# Example Query - ArXiv Search\nquery = \"Agentic AI Design Patterns\"\n\n# Run the query and evaluate\ntry:\n    response = await run_agent(query)\n    if response.strip():\n        evaluate_response(response)\n    else:\n        print(\"No response received to evaluate.\")\nexcept Exception as e:\n    print(f\"Failed to run agent: {e}\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:00:20.404218Z","iopub.execute_input":"2025-11-30T22:00:20.404555Z","iopub.status.idle":"2025-11-30T22:01:00.542038Z","shell.execute_reply.started":"2025-11-30T22:00:20.404524Z","shell.execute_reply":"2025-11-30T22:01:00.540877Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Session service and runner initialized.\n   - Application: research_agent\n   - User: researcher_01\n   - Using: InMemorySessionService\nUser > Agentic AI Design Patterns\n--------------------------------------------------\nü§ñ Agent is calling tool: researcher_agent\nü§ñ Agent is calling tool: analyst_agent\nü§ñ Agent is calling tool: formatter_agent\nü§ñ Agent is calling tool: save_to_memory\nAgent > I have researched the topic \"Agentic AI Design Patterns.\" Here are the formatted citations for the papers I found:\n\n1.  ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration - Authors: Hongjin Su, Shizhe Diao, Ximing Lu et al. Published: 2025-11-26 URL: http://arxiv.org/abs/2511.21689v1\n2.  G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning - Authors: Wenbo Hu, Jingli Lin, Yilin Long et al. Published: 2025-11-26 URL: http://arxiv.org/abs/2511.21688v1\n3.  Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework - Authors: Dong Wang, Yang Li, Ansong Ni et al. Published: 2025-11-26 URL: http://arxiv.org/abs/2511.21686v1\n4.  Agentic Learner with Grow-and-Refine Multimodal Semantic Memory - Authors: Weihao Bo, Shan Zhang, Yanpeng Sun et al. Published: 2025-11-26 URL: http://arxiv.org/abs/2511.21678v1\n5.  On Evolution-Based Models for Experimentation Under Interference - Authors: Sadegh Shirani, Mohsen Bayati Published: 2025-11-26 URL: http://arxiv.org/abs/2511.21675v1\n\nRegarding the publication year analysis, all the papers retrieved for \"Agentic AI Design Patterns\" were published in 2025. This indicates that this is a very recent and active area of research.\n\n\nAgent > ```\nPublication Year Analysis for Agentic AI Design Patterns\n-----------------------------------------------------\n2025 | ***** (5 papers)\n```\nAgent > \n\nThe information, including the analysis and citations, has been saved to your knowledge base under the key \"Agentic AI Design Patterns\".\n\n--- Evaluation Results ---\nScore: 5/5\nChecks passed: List format detected, Recent years detected, URLs detected, Analysis/Chart detected, Memory save confirmed\n","output_type":"stream"}],"execution_count":11},{"id":"f127094f","cell_type":"markdown","source":"## üöÄ 6. Deploy to Vertex AI Agent Engine\n\nVertex AI Agent Engine allows you to deploy and scale your AI agents in production. Here's how to prepare and deploy your agent.\n\n### 6.1: Install Vertex AI SDK","metadata":{}},{"id":"40defdab","cell_type":"code","source":"!pip install google-cloud-aiplatform\n\nprint(\"‚úÖ Vertex AI SDK installed.\")","metadata":{},"outputs":[],"execution_count":null},{"id":"93541d44","cell_type":"markdown","source":"### 6.2: Configure Google Cloud Project\n\nSet up your Google Cloud project credentials for Vertex AI deployment.","metadata":{}},{"id":"f9242ac8","cell_type":"code","source":"from google.cloud import aiplatform\n\n# Configure your Google Cloud project\nPROJECT_ID = \"your-project-id\"  # Replace with your GCP project ID\nLOCATION = \"us-central1\"  # Choose your preferred region\nSTAGING_BUCKET = \"gs://your-bucket-name\"  # Replace with your GCS bucket\n\n# Initialize Vertex AI\naiplatform.init(\n    project=PROJECT_ID,\n    location=LOCATION,\n    staging_bucket=STAGING_BUCKET\n)\n\nprint(f\"‚úÖ Vertex AI initialized for project: {PROJECT_ID}\")","metadata":{},"outputs":[],"execution_count":null},{"id":"9f0e4d4e","cell_type":"markdown","source":"### 6.3: Create Agent Package (Multi-Agent)\n\nCreate the agent files needed for deployment. We will package our full **Multi-Agent System** (Researcher, Analyst, Formatter, Root) into the `agent.py` file.","metadata":{}},{"id":"7d4d09fb","cell_type":"code","source":"import os\n\n# Create deployment directory\nos.makedirs(\"vertex_agent_deployment\", exist_ok=True)\n\n# Create agent.py - Main agent file\nagent_code = \"\"\"\nimport arxiv\nimport json\nimport os\nimport logging\nfrom typing import List, Any\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.tools import AgentTool\nfrom google.genai import types\n\n# Configure Logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# --- Tools ---\n\ndef search_arxiv(query: str, max_results: int = 5) -> str:\n    \\\"\\\"\\\"Searches ArXiv for research papers matching the query.\\\"\\\"\\\"\n    try:\n        search = arxiv.Search(\n            query=query,\n            max_results=max_results,\n            sort_by=arxiv.SortCriterion.SubmittedDate\n        )\n        \n        results = []\n        for paper in search.results():\n            result = {\n                \"title\": paper.title,\n                \"authors\": [author.name for author in paper.authors],\n                \"summary\": paper.summary[:300] + \"...\" if len(paper.summary) > 300 else paper.summary,\n                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n                \"url\": paper.entry_id,\n            }\n            results.append(result)\n            \n        if not results:\n            return f\"No papers found for query: {query}\"\n\n        formatted = f\"Found {len(results)} papers for '{query}':\\\\n\\\\n\"\n        for i, paper in enumerate(results, 1):\n            authors = \", \".join(paper[\"authors\"][:3])\n            if len(paper[\"authors\"]) > 3:\n                authors += \" et al.\"\n            formatted += f\"{i}. **{paper['title']}**\\\\n\"\n            formatted += f\"   Authors: {authors}\\\\n\"\n            formatted += f\"   Published: {paper['published']}\\\\n\"\n            formatted += f\"   URL: {paper['url']}\\\\n\"\n            formatted += f\"   Summary: {paper['summary']}\\\\n\\\\n\"\n        return formatted\n    except Exception as e:\n        return f\"Error searching ArXiv: {str(e)}\"\n\ndef format_citation(title: str, authors: List[str], year: str, url: str) -> str:\n    \\\"\\\"\\\"Formats a research paper citation.\\\"\\\"\\\"\n    author_str = \", \".join(authors)\n    return f\"{author_str} ({year}). **{title}**. Retrieved from {url}\"\n\n# Use /tmp for writable location in cloud environments\nMEMORY_FILE = \"/tmp/knowledge_base.json\"\n\ndef save_to_memory(key: str, value: Any) -> str:\n    \\\"\\\"\\\"Saves a key-value pair to a persistent JSON file.\\\"\\\"\\\"\n    try:\n        if os.path.exists(MEMORY_FILE):\n            with open(MEMORY_FILE, 'r') as f:\n                data = json.load(f)\n        else:\n            data = {}\n            \n        data[key] = value\n        \n        with open(MEMORY_FILE, 'w') as f:\n            json.dump(data, f, indent=2)\n            \n        return f\"Successfully saved '{key}' to long-term memory.\"\n    except Exception as e:\n        return f\"Error saving to memory: {str(e)}\"\n\n# --- Agents ---\n\nretry_config = types.HttpRetryOptions(\n    attempts=3,\n    exp_base=2,\n    initial_delay=1,\n    http_status_codes=[429, 500, 503],\n)\n\n# Shared Model\nmodel = Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config)\n\n# 1. Researcher Agent\nresearcher_agent = LlmAgent(\n    name=\"researcher_agent\",\n    model=model,\n    description=\"Searches for research papers using ArXiv API.\",\n    instruction='''\n    You are a research assistant with access to ArXiv.\n    When given a research topic:\n    1. Use the 'search_arxiv' tool to find relevant academic papers.\n    2. Focus on recent papers (2023-2025 when possible).\n    3. Return the paper details including titles, authors, dates, and URLs.\n    ''',\n    tools=[search_arxiv]\n)\n\n# 2. Analyst Agent\nanalyst_agent = LlmAgent(\n    name=\"analyst_agent\",\n    model=model,\n    description=\"Analyzes research data and creates visualizations.\",\n    instruction='''\n    You are a data analyst.\n    Given a list of research papers or search results:\n    1. Extract the publication years from the paper information.\n    2. Calculate the distribution of papers by year.\n    3. Create a simple ASCII bar chart showing the distribution.\n    4. Return the analysis summary and the ASCII chart.\n    '''\n)\n\n# 3. Formatter Agent\nformatter_agent = LlmAgent(\n    name=\"formatter_agent\",\n    model=model,\n    description=\"Formats paper details into proper citations.\",\n    instruction='''\n    You are a citation expert. \n    Take the raw paper information and format it into clean academic citations.\n    Use APA format: Authors (Year). Title. Retrieved from URL\n    Return the final list of formatted citations as a numbered list.\n    '''\n)\n\n# 4. Root Agent (Orchestrator)\nroot_agent = LlmAgent(\n    name=\"root_agent\",\n    model=model,\n    instruction='''\n    You are the Lead Research Coordinator.\n    \n    Your workflow is:\n    1. **Research**: Delegate to 'researcher_agent' to find papers on the user's topic.\n    2. **Analyze**: Delegate the findings to 'analyst_agent' to get a distribution of publication years.\n    3. **Format**: Delegate to 'formatter_agent' to get a list of citations.\n    4. **Save**: Use the 'save_to_memory' tool to save the final citation list and analysis to the 'knowledge_base.json' file. Use the topic as the key.\n    5. **Report**: YOU MUST PRINT the final report to the user.\n       - Show the \"Formatted Citations\" list.\n       - Show the \"Publication Year Analysis\" chart.\n       - Confirm that data has been saved to memory.\n       \n    CRITICAL: Do NOT stop after calling tools. You MUST generate a final text response summarizing the results.\n    ''',\n    tools=[\n        AgentTool(agent=researcher_agent), \n        AgentTool(agent=analyst_agent), \n        AgentTool(agent=formatter_agent),\n        save_to_memory\n    ]\n)\n\n# Export the root agent\nagent = root_agent\n\"\"\"\n\nwith open(\"vertex_agent_deployment/agent.py\", \"w\") as f:\n    f.write(agent_code)\n\n# Create requirements.txt\nrequirements = \"\"\"google-adk\narxiv\ngoogle-cloud-aiplatform\n\"\"\"\n\nwith open(\"vertex_agent_deployment/requirements.txt\", \"w\") as f:\n    f.write(requirements)\n\n# Create deployment config\nconfig = \"\"\"{\n  \"agent_name\": \"research-assistant\",\n  \"agent_description\": \"Multi-agent academic research system\",\n  \"model\": \"gemini-2.5-flash-lite\"\n}\n\"\"\"\n\nwith open(\"vertex_agent_deployment/config.json\", \"w\") as f:\n    f.write(config)\n\nprint(\"‚úÖ Agent package created in 'vertex_agent_deployment/' directory\")\nprint(\"   - agent.py: Multi-agent system code\")\nprint(\"   - requirements.txt: Dependencies\")\nprint(\"   - config.json: Deployment configuration\")","metadata":{},"outputs":[],"execution_count":null},{"id":"4f747130","cell_type":"markdown","source":"### 6.4: Deploy to Vertex AI Agent Engine\n\nNow that the agent package is created in the `vertex_agent_deployment/` directory, you can deploy it to Vertex AI.\n\nYou can use the Google Cloud CLI (`gcloud`) to deploy your agent. Run the following command in your terminal (ensure you have authenticated with `gcloud auth login`):\n\n```bash\ngcloud beta ai agents create \\\n  --display-name=\"Research Assistant\" \\\n  --project=$PROJECT_ID \\\n  --location=$LOCATION \\\n  --agent-package-path=\"vertex_agent_deployment/\"\n```\n\nAlternatively, you can zip the folder and upload it via the Google Cloud Console.","metadata":{}},{"id":"57af8651","cell_type":"markdown","source":"### 6.5: Test Deployed Agent\n\nOnce deployed, you can interact with your agent via the Vertex AI API.","metadata":{}},{"id":"ad14931e","cell_type":"code","source":"# Example: Interacting with deployed agent\ntest_code = '''\nfrom google.cloud import aiplatform\nfrom google.genai.types import Content, Part\n\n# Initialize the agent client\nAGENT_ID = \"your-agent-id\"  # Replace with your deployed agent ID\n\n# Create a prediction request\ndef query_deployed_agent(query: str):\n    \"\"\"Query the deployed Vertex AI agent.\"\"\"\n    \n    endpoint = aiplatform.Endpoint(\n        endpoint_name=f\"projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{AGENT_ID}\"\n    )\n    \n    # Format the request\n    message = Content(parts=[Part(text=query)], role=\"user\")\n    \n    # Send request\n    response = endpoint.predict(instances=[{\"message\": message}])\n    \n    return response.predictions[0]\n\n# Test the deployed agent\ntry:\n    result = query_deployed_agent(\"Search for papers on transformers in NLP\")\n    print(\"Agent Response:\", result)\nexcept Exception as e:\n    print(f\"Note: Replace AGENT_ID and ensure agent is deployed. Error: {e}\")\n'''\n\nprint(\"üí¨ Example code to query your deployed agent:\")\nprint(test_code)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"REST API Example:\")\nprint(\"=\"*60)\n\nrest_example = f'''\ncurl -X POST \\\\\n  https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/agents/AGENT_ID:query \\\\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -d '{{\n    \"message\": \"Search for papers on quantum computing\",\n    \"session_id\": \"unique-session-id\"\n  }}'\n'''\n\nprint(rest_example)","metadata":{},"outputs":[],"execution_count":null},{"id":"ef87063a","cell_type":"markdown","source":"## üîß 7. Alternative Deployment: Flask API (Local Testing)\n\nFor local testing and development, you can wrap the agent in a **Flask** application. This is useful for testing before deploying to Vertex AI.\n\n*Note: This is for local development only. Use Vertex AI Agent Engine for production deployments.*\n\n### 7.1: Create Flask API Server","metadata":{}},{"id":"18912d7e","cell_type":"code","source":"from flask import Flask, request, jsonify\nimport threading\nfrom IPython.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\nimport nest_asyncio\nimport asyncio\n\n# Apply nest_asyncio to allow nested event loops\nnest_asyncio.apply()\n\n# Capture the main event loop where the runner was initialized\ntry:\n    MAIN_LOOP = asyncio.get_running_loop()\nexcept RuntimeError:\n    MAIN_LOOP = asyncio.new_event_loop()\n    asyncio.set_event_loop(MAIN_LOOP)\n\n# Define the Flask App\napp = Flask(__name__)\n\ndef run_agent_sync(query: str, session_id: str):\n    \"\"\"\n    Synchronous wrapper that runs the async agent on the main event loop.\n    This avoids 'attached to a different loop' errors by ensuring the runner\n    executes in the same loop where it was created.\n    \"\"\"\n    from google.genai.types import Content, Part\n    \n    async def run_agent_task():\n        # Create or get session\n        try:\n            session = await session_service.create_session(\n                app_name=APP_NAME, \n                user_id=USER_ID, \n                session_id=session_id\n            )\n        except:\n            session = await session_service.get_session(\n                app_name=APP_NAME, \n                user_id=USER_ID, \n                session_id=session_id\n            )\n        \n        full_response = \"\"\n        message = Content(parts=[Part(text=query)], role=\"user\")\n        \n        # Run the agent\n        async for event in runner.run_async(\n            user_id=USER_ID, \n            session_id=session.id,\n            new_message=message\n        ):\n            if event.content and event.content.parts:\n                part = event.content.parts[0]\n                if part.text and part.text != \"None\":\n                    print(f\"Agent > {part.text}\")\n                    full_response += part.text + \"\\n\"\n        \n        return full_response\n    \n    # Submit the task to the main loop from the Flask thread\n    future = asyncio.run_coroutine_threadsafe(run_agent_task(), MAIN_LOOP)\n    return future.result()\n\n@app.route('/chat', methods=['POST'])\ndef chat_endpoint():\n    \"\"\"\n    API Endpoint to interact with the Research Agent.\n    Expected JSON: {\"query\": \"your research topic\", \"session_id\": \"optional_session_id\"}\n    \"\"\"\n    data = request.json\n    query = data.get('query')\n    session_id = data.get('session_id', 'default_session')\n    \n    if not query:\n        return jsonify({\"error\": \"No query provided\"}), 400\n    \n    print(f\"API Request: {query}\")\n    \n    # Run the agent\n    try:\n        response_text = run_agent_sync(query, session_id)\n        return jsonify({\"response\": response_text, \"status\": \"success\"})\n    except Exception as e:\n        import traceback\n        error_details = traceback.format_exc()\n        print(f\"Error details: {error_details}\")\n        return jsonify({\"error\": str(e), \"status\": \"failed\"}), 500\n\n@app.route('/health', methods=['GET'])\ndef health_check():\n    \"\"\"Health check endpoint\"\"\"\n    return jsonify({\"status\": \"healthy\", \"agent\": \"Research Assistant\"})\n\ndef run_flask():\n    \"\"\"Runs the Flask app on port 5003.\"\"\"\n    app.run(host='0.0.0.0', port=5003, debug=False, use_reloader=False)\n\ndef get_flask_proxy_url():\n    \"\"\"Get the Kaggle proxy URL for Flask\"\"\"\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    FLASK_PORT = \"5003\"\n    \n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n    \n    baseURL = servers[0]['base_url']\n    \n    try:\n        path_parts = baseURL.split('/')\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n    \n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{FLASK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n    \n    styled_html = f\"\"\"\n    <div style=\"padding: 20px; border: 2px solid #4CAF50; border-radius: 8px; background-color: #f0fdf4; margin: 20px 0;\">\n        <h3 style=\"color: #2e7d32; margin-top: 0;\">üöÄ Flask API Running!</h3>\n        <p style=\"font-family: sans-serif; color: #333;\">Your Research Assistant API is now accessible.</p>\n        \n        <div style=\"background-color: white; padding: 15px; border-radius: 5px; margin: 15px 0;\">\n            <strong>Endpoints:</strong><br>\n            <code style=\"background-color: #f5f5f5; padding: 2px 6px; border-radius: 3px;\">POST {url}/chat</code> - Query the agent<br>\n            <code style=\"background-color: #f5f5f5; padding: 2px 6px; border-radius: 3px;\">GET {url}/health</code> - Health check\n        </div>\n        \n        <div style=\"background-color: #fff3cd; padding: 15px; border-radius: 5px; margin: 15px 0; border-left: 4px solid #ffc107;\">\n            <strong>Example cURL command:</strong><br>\n            <code style=\"display: block; margin-top: 10px; padding: 10px; background-color: #2d2d2d; color: #f8f8f2; border-radius: 3px; overflow-x: auto;\">\ncurl -X POST \"{url}/chat\" \\\\<br>\n  -H \"Content-Type: application/json\" \\\\<br>\n  -d '{{\"query\": \"Search for papers on quantum computing\"}}'\n            </code>\n        </div>\n        \n        <a href='{url}/health' target='_blank' style=\"\n            display: inline-block; background-color: #4CAF50; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease; margin-top: 10px;\">\n            Test Health Check ‚Üó\n        </a>\n    </div>\n    \"\"\"\n    \n    display(HTML(styled_html))\n    return url\n\n# Start Flask in background\nflask_thread = threading.Thread(target=run_flask, daemon=True)\nflask_thread.start()\n\nprint(\"‚úÖ Flask API server starting...\")\nprint(\"Run the next cell to get your API URL!\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:01:36.00092Z","iopub.execute_input":"2025-11-30T22:01:36.001236Z","iopub.status.idle":"2025-11-30T22:01:36.37156Z","shell.execute_reply.started":"2025-11-30T22:01:36.001215Z","shell.execute_reply":"2025-11-30T22:01:36.368425Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Flask API server starting...\nRun the next cell to get your API URL!\n * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"},{"name":"stderr","text":"INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n * Running on all addresses (0.0.0.0)\n * Running on http://127.0.0.1:5003\n * Running on http://172.19.2.2:5003\nINFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","output_type":"stream"}],"execution_count":12},{"id":"84e02b03-7138-4e19-87bd-757c58c857f5","cell_type":"markdown","source":"---\n\n### 7.2: Get Your Flask API URL\n\nGet your custom URL to access the Flask API in the Kaggle Notebooks environment:","metadata":{}},{"id":"f6a942f3-40af-4815-a1a6-92d8a8a34d76","cell_type":"code","source":"# Get and display the Flask API URL\nflask_api_url = get_flask_proxy_url()","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:01:43.890165Z","iopub.execute_input":"2025-11-30T22:01:43.890509Z","iopub.status.idle":"2025-11-30T22:01:43.899433Z","shell.execute_reply.started":"2025-11-30T22:01:43.89047Z","shell.execute_reply":"2025-11-30T22:01:43.898334Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div style=\"padding: 20px; border: 2px solid #4CAF50; border-radius: 8px; background-color: #f0fdf4; margin: 20px 0;\">\n        <h3 style=\"color: #2e7d32; margin-top: 0;\">üöÄ Flask API Running!</h3>\n        <p style=\"font-family: sans-serif; color: #333;\">Your Research Assistant API is now accessible.</p>\n        \n        <div style=\"background-color: white; padding: 15px; border-radius: 5px; margin: 15px 0;\">\n            <strong>Endpoints:</strong><br>\n            <code style=\"background-color: #f5f5f5; padding: 2px 6px; border-radius: 3px;\">POST https://kkb-production.jupyter-proxy.kaggle.net/k/282969130/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..pE8JqCFdrOMSC9IJFtKVmQ.uSmRbkcdFuyey4cwSN3l9ssXI7L3ZUGXbHo2w6dSYeKe2p_EbmV0DKX1dJNNPDUb9TrB9HFc5-YOPGj1Z5Z2IiPoOgqNEmeVYKnE6YZILcFR0jyPvDfu7Z8v0HZS1jSsYS8eQELPNcoJz7fGvPAN97jQGFcw_87ehgU5hwW8jb9QN5heLQ-1Se764G3o964YDXk6beafOYW4hAYHCoP5wg5aIm5Hkj53GFgFaPmyxEC09dRUuLqJvjL9hj6AjJEK.vCANzVxJVtCdxifIQTQ8_g/proxy/proxy/5003/chat</code> - Query the agent<br>\n            <code style=\"background-color: #f5f5f5; padding: 2px 6px; border-radius: 3px;\">GET https://kkb-production.jupyter-proxy.kaggle.net/k/282969130/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..pE8JqCFdrOMSC9IJFtKVmQ.uSmRbkcdFuyey4cwSN3l9ssXI7L3ZUGXbHo2w6dSYeKe2p_EbmV0DKX1dJNNPDUb9TrB9HFc5-YOPGj1Z5Z2IiPoOgqNEmeVYKnE6YZILcFR0jyPvDfu7Z8v0HZS1jSsYS8eQELPNcoJz7fGvPAN97jQGFcw_87ehgU5hwW8jb9QN5heLQ-1Se764G3o964YDXk6beafOYW4hAYHCoP5wg5aIm5Hkj53GFgFaPmyxEC09dRUuLqJvjL9hj6AjJEK.vCANzVxJVtCdxifIQTQ8_g/proxy/proxy/5003/health</code> - Health check\n        </div>\n        \n        <div style=\"background-color: #fff3cd; padding: 15px; border-radius: 5px; margin: 15px 0; border-left: 4px solid #ffc107;\">\n            <strong>Example cURL command:</strong><br>\n            <code style=\"display: block; margin-top: 10px; padding: 10px; background-color: #2d2d2d; color: #f8f8f2; border-radius: 3px; overflow-x: auto;\">\ncurl -X POST \"https://kkb-production.jupyter-proxy.kaggle.net/k/282969130/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..pE8JqCFdrOMSC9IJFtKVmQ.uSmRbkcdFuyey4cwSN3l9ssXI7L3ZUGXbHo2w6dSYeKe2p_EbmV0DKX1dJNNPDUb9TrB9HFc5-YOPGj1Z5Z2IiPoOgqNEmeVYKnE6YZILcFR0jyPvDfu7Z8v0HZS1jSsYS8eQELPNcoJz7fGvPAN97jQGFcw_87ehgU5hwW8jb9QN5heLQ-1Se764G3o964YDXk6beafOYW4hAYHCoP5wg5aIm5Hkj53GFgFaPmyxEC09dRUuLqJvjL9hj6AjJEK.vCANzVxJVtCdxifIQTQ8_g/proxy/proxy/5003/chat\" \\<br>\n  -H \"Content-Type: application/json\" \\<br>\n  -d '{\"query\": \"Search for papers on quantum computing\"}'\n            </code>\n        </div>\n        \n        <a href='https://kkb-production.jupyter-proxy.kaggle.net/k/282969130/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..pE8JqCFdrOMSC9IJFtKVmQ.uSmRbkcdFuyey4cwSN3l9ssXI7L3ZUGXbHo2w6dSYeKe2p_EbmV0DKX1dJNNPDUb9TrB9HFc5-YOPGj1Z5Z2IiPoOgqNEmeVYKnE6YZILcFR0jyPvDfu7Z8v0HZS1jSsYS8eQELPNcoJz7fGvPAN97jQGFcw_87ehgU5hwW8jb9QN5heLQ-1Se764G3o964YDXk6beafOYW4hAYHCoP5wg5aIm5Hkj53GFgFaPmyxEC09dRUuLqJvjL9hj6AjJEK.vCANzVxJVtCdxifIQTQ8_g/proxy/proxy/5003/health' target='_blank' style=\"\n            display: inline-block; background-color: #4CAF50; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease; margin-top: 10px;\">\n            Test Health Check ‚Üó\n        </a>\n    </div>\n    "},"metadata":{}}],"execution_count":13},{"id":"b63f1b20-8172-472c-b61f-06058712ea9e","cell_type":"markdown","source":"### 7.3: Test Your API\n\nNow you can test your Flask API using cURL, Python requests, or any HTTP client!","metadata":{}},{"id":"d5e77a7d-f4c6-4465-946a-70e11ba2c321","cell_type":"code","source":"# Example: Test the API using Python requests\nimport requests\nimport json\nimport threading\n\ndef test_api():\n    # Test health check\n    print(\"Testing health endpoint...\")\n    try:\n        health_response = requests.get(f\"{flask_api_url}/health\")\n        print(f\"Health check: {health_response.json()}\")\n    except Exception as e:\n        print(f\"Note: Run this after getting the URL from the previous cell. Error: {e}\")\n\n    # Test chat endpoint\n    print(\"\\nTesting chat endpoint...\")\n    test_query = {\n        \"query\": \"Find papers on transformer neural networks\",\n        \"session_id\": \"test_session_001\"\n    }\n\n    try:\n        print(\"Sending request (this may take 30-60s)...\")\n        chat_response = requests.post(\n            f\"{flask_api_url}/chat\",\n            headers={\"Content-Type\": \"application/json\"},\n            data=json.dumps(test_query)\n        )\n        print(f\"Chat response: {chat_response.json()}\")\n    except Exception as e:\n        print(f\"Note: Make sure Flask is running. Error: {e}\")\n\n# Run the test in a separate thread to avoid blocking the Main Event Loop\n# (which is needed by the Agent running in the Flask server)\ntest_thread = threading.Thread(target=test_api)\ntest_thread.start()","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:01:49.801461Z","iopub.execute_input":"2025-11-30T22:01:49.802375Z","iopub.status.idle":"2025-11-30T22:01:49.812673Z","shell.execute_reply.started":"2025-11-30T22:01:49.802346Z","shell.execute_reply":"2025-11-30T22:01:49.811609Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Testing health endpoint...\n","output_type":"stream"},{"name":"stderr","text":"INFO:werkzeug:127.0.0.1 - - [30/Nov/2025 22:01:49] \"GET /health HTTP/1.1\" 200 -\n","output_type":"stream"},{"name":"stdout","text":"Health check: {'agent': 'Research Assistant', 'status': 'healthy'}\n\nTesting chat endpoint...\nSending request (this may take 30-60s)...\nAPI Request: Find papers on transformer neural networks\n","output_type":"stream"},{"name":"stderr","text":"INFO:werkzeug:127.0.0.1 - - [30/Nov/2025 22:02:02] \"POST /chat HTTP/1.1\" 200 -\n","output_type":"stream"},{"name":"stdout","text":"Agent > Here is a summary of the papers found on transformer neural networks:\n\n**Formatted Citations:**\n1. Lee, S., Jung, Y., Chun, I., et al. (2025). TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos. Retrieved from http://arxiv.org/abs/2511.21690v1\n2. Vijay, A., & Lee, J. Y. (2025). Holographically Emergent Gauge Theory in Symmetric Quantum Circuits. Retrieved from http://arxiv.org/abs/2511.21685v1\n3. Shirani, S., & Bayati, M. (2025). On Evolution-Based Models for Experimentation Under Interference. Retrieved from http://arxiv.org/abs/2511.21675v1\n4. Korcsak-Gorzo, A., Valverde, J. A. E., Stapmanns, J., et al. (2025). Event-driven eligibility propagation in large sparse networks: efficiency shaped by biological realism. Retrieved from http://arxiv.org/abs/2511.21674v1\n5. V., P., Mynampati, S., Karthik, A., et al. (2025). Revolutionizing Glioma Segmentation & Grading Using 3D MRI - Guided Hybrid Deep Learning Models. Retrieved from http://arxiv.org/abs/2511.21673v1\n\n**Publication Year Analysis:**\n2025: ***** (5 papers)\n\nThe data has been saved to memory.\nChat response: {'response': 'Here is a summary of the papers found on transformer neural networks:\\n\\n**Formatted Citations:**\\n1. Lee, S., Jung, Y., Chun, I., et al. (2025). TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos. Retrieved from http://arxiv.org/abs/2511.21690v1\\n2. Vijay, A., & Lee, J. Y. (2025). Holographically Emergent Gauge Theory in Symmetric Quantum Circuits. Retrieved from http://arxiv.org/abs/2511.21685v1\\n3. Shirani, S., & Bayati, M. (2025). On Evolution-Based Models for Experimentation Under Interference. Retrieved from http://arxiv.org/abs/2511.21675v1\\n4. Korcsak-Gorzo, A., Valverde, J. A. E., Stapmanns, J., et al. (2025). Event-driven eligibility propagation in large sparse networks: efficiency shaped by biological realism. Retrieved from http://arxiv.org/abs/2511.21674v1\\n5. V., P., Mynampati, S., Karthik, A., et al. (2025). Revolutionizing Glioma Segmentation & Grading Using 3D MRI - Guided Hybrid Deep Learning Models. Retrieved from http://arxiv.org/abs/2511.21673v1\\n\\n**Publication Year Analysis:**\\n2025: ***** (5 papers)\\n\\nThe data has been saved to memory.\\n', 'status': 'success'}\n","output_type":"stream"}],"execution_count":14},{"id":"5e4bd17b-f1e5-458a-b56d-4d0a47294622","cell_type":"markdown","source":"### 7.4: Using the API from External Tools\n\nYou can also use the API from external tools like Postman, Insomnia, or your own applications.\n\n**Important Security Notes:**\n- ‚ö†Ô∏è **DO NOT SHARE YOUR API URL** - it contains authentication tokens\n- This is for development/testing only\n- For production, deploy to a proper server with authentication\n\nThe Flask API is now ready to receive research queries and return formatted results!","metadata":{}},{"id":"052cceb2","cell_type":"markdown","source":"## üíª 8. Try the ADK Web Interface\n\nADK includes a built-in web interface for interactively chatting with, testing, and debugging your agents.\n\n<img width=\"1200\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/adk-web-ui.gif\" alt=\"ADK Web UI\" />\n\nTo use the ADK web UI, you'll need to create an agent with Python files using the `adk create` command.\n\nRun the command below to generate a `research-agent` folder that contains all the necessary files, including `agent.py` for your code, an `.env` file with your API key pre-configured, and an `__init__.py` file.\n\n### 8.1: Create Research Agent","metadata":{}},{"id":"eeaa7398","cell_type":"code","source":"!adk create research-agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:02:08.606018Z","iopub.execute_input":"2025-11-30T22:02:08.606389Z","iopub.status.idle":"2025-11-30T22:02:38.364639Z","shell.execute_reply.started":"2025-11-30T22:02:08.606354Z","shell.execute_reply":"2025-11-30T22:02:38.363448Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[32m\nAgent created in /kaggle/working/research-agent:\n- .env\n- __init__.py\n- agent.py\n\u001b[0m\n","output_type":"stream"}],"execution_count":15},{"id":"b3de9bac","cell_type":"markdown","source":"---\n\n### 8.2: Update Agent Code\n\nThe `adk create` command generates a basic template. We will now overwrite the generated `agent.py` with our complete **Multi-Agent System** code so that the Web UI uses the full functionality we built.","metadata":{}},{"id":"590c456f","cell_type":"code","source":"# Overwrite the generated agent.py with our Multi-Agent System code\nagent_code = \"\"\"\nimport arxiv\nimport json\nimport os\nimport logging\nfrom typing import List, Any\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.tools import AgentTool\nfrom google.genai import types\n\n# Configure Logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# --- Tools ---\n\ndef search_arxiv(query: str, max_results: int = 5) -> str:\n    \\\"\\\"\\\"Searches ArXiv for research papers matching the query.\\\"\\\"\\\"\n    try:\n        search = arxiv.Search(\n            query=query,\n            max_results=max_results,\n            sort_by=arxiv.SortCriterion.SubmittedDate\n        )\n        \n        results = []\n        for paper in search.results():\n            result = {\n                \"title\": paper.title,\n                \"authors\": [author.name for author in paper.authors],\n                \"summary\": paper.summary[:300] + \"...\" if len(paper.summary) > 300 else paper.summary,\n                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n                \"url\": paper.entry_id,\n            }\n            results.append(result)\n            \n        if not results:\n            return f\"No papers found for query: {query}\"\n\n        formatted = f\"Found {len(results)} papers for '{query}':\\\\n\\\\n\"\n        for i, paper in enumerate(results, 1):\n            authors = \", \".join(paper[\"authors\"][:3])\n            if len(paper[\"authors\"]) > 3:\n                authors += \" et al.\"\n            formatted += f\"{i}. **{paper['title']}**\\\\n\"\n            formatted += f\"   Authors: {authors}\\\\n\"\n            formatted += f\"   Published: {paper['published']}\\\\n\"\n            formatted += f\"   URL: {paper['url']}\\\\n\"\n            formatted += f\"   Summary: {paper['summary']}\\\\n\\\\n\"\n        return formatted\n    except Exception as e:\n        return f\"Error searching ArXiv: {str(e)}\"\n\ndef format_citation(title: str, authors: List[str], year: str, url: str) -> str:\n    \\\"\\\"\\\"Formats a research paper citation.\\\"\\\"\\\"\n    author_str = \", \".join(authors)\n    return f\"{author_str} ({year}). **{title}**. Retrieved from {url}\"\n\n# Use /tmp for writable location in cloud environments\nMEMORY_FILE = \"/tmp/knowledge_base.json\"\n\ndef save_to_memory(key: str, value: Any) -> str:\n    \\\"\\\"\\\"Saves a key-value pair to a persistent JSON file.\\\"\\\"\\\"\n    try:\n        if os.path.exists(MEMORY_FILE):\n            with open(MEMORY_FILE, 'r') as f:\n                data = json.load(f)\n        else:\n            data = {}\n            \n        data[key] = value\n        \n        with open(MEMORY_FILE, 'w') as f:\n            json.dump(data, f, indent=2)\n            \n        return f\"Successfully saved '{key}' to long-term memory.\"\n    except Exception as e:\n        return f\"Error saving to memory: {str(e)}\"\n\n# --- Agents ---\n\nretry_config = types.HttpRetryOptions(\n    attempts=3,\n    exp_base=2,\n    initial_delay=1,\n    http_status_codes=[429, 500, 503],\n)\n\n# Shared Model\nmodel = Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config)\n\n# 1. Researcher Agent\nresearcher_agent = LlmAgent(\n    name=\"researcher_agent\",\n    model=model,\n    description=\"Searches for research papers using ArXiv API.\",\n    instruction='''\n    You are a research assistant with access to ArXiv.\n    When given a research topic:\n    1. Use the 'search_arxiv' tool to find relevant academic papers.\n    2. Focus on recent papers (2023-2025 when possible).\n    3. Return the paper details including titles, authors, dates, and URLs.\n    ''',\n    tools=[search_arxiv]\n)\n\n# 2. Analyst Agent\nanalyst_agent = LlmAgent(\n    name=\"analyst_agent\",\n    model=model,\n    description=\"Analyzes research data and creates visualizations.\",\n    instruction='''\n    You are a data analyst.\n    Given a list of research papers or search results:\n    1. Extract the publication years from the paper information.\n    2. Calculate the distribution of papers by year.\n    3. Create a simple ASCII bar chart showing the distribution.\n    4. Return the analysis summary and the ASCII chart.\n    '''\n)\n\n# 3. Formatter Agent\nformatter_agent = LlmAgent(\n    name=\"formatter_agent\",\n    model=model,\n    description=\"Formats paper details into proper citations.\",\n    instruction='''\n    You are a citation expert. \n    Take the raw paper information and format it into clean academic citations.\n    Use APA format: Authors (Year). Title. Retrieved from URL\n    Return the final list of formatted citations as a numbered list.\n    '''\n)\n\n# 4. Root Agent (Orchestrator)\nroot_agent = LlmAgent(\n    name=\"root_agent\",\n    model=model,\n    instruction='''\n    You are the Lead Research Coordinator.\n    \n    Your workflow is:\n    1. **Research**: Delegate to 'researcher_agent' to find papers on the user's topic.\n    2. **Analyze**: Delegate the findings to 'analyst_agent' to get a distribution of publication years.\n    3. **Format**: Delegate to 'formatter_agent' to get a list of citations.\n    4. **Save**: Use the 'save_to_memory' tool to save the final citation list and analysis to the 'knowledge_base.json' file. Use the topic as the key.\n    5. **Report**: YOU MUST PRINT the final report to the user.\n       - Show the \"Formatted Citations\" list.\n       - Show the \"Publication Year Analysis\" chart.\n       - Confirm that data has been saved to memory.\n       \n    CRITICAL: Do NOT stop after calling tools. You MUST generate a final text response summarizing the results.\n    ''',\n    tools=[\n        AgentTool(agent=researcher_agent), \n        AgentTool(agent=analyst_agent), \n        AgentTool(agent=formatter_agent),\n        save_to_memory\n    ]\n)\n\n# Export the root agent\nagent = root_agent\n\"\"\"\n\nwith open(\"research-agent/agent.py\", \"w\") as f:\n    f.write(agent_code)\n\n# Update requirements.txt to include arxiv\nrequirements = \"\"\"google-adk\narxiv\n\"\"\"\n\nwith open(\"research-agent/requirements.txt\", \"w\") as f:\n    f.write(requirements)\n\nprint(\"‚úÖ Updated 'research-agent/agent.py' with Multi-Agent System code.\")\nprint(\"‚úÖ Updated 'research-agent/requirements.txt' with dependencies.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T22:03:06.417728Z","iopub.execute_input":"2025-11-30T22:03:06.418083Z","iopub.status.idle":"2025-11-30T22:03:06.430241Z","shell.execute_reply.started":"2025-11-30T22:03:06.418054Z","shell.execute_reply":"2025-11-30T22:03:06.42843Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Updated 'research-agent/agent.py' with Multi-Agent System code.\n‚úÖ Updated 'research-agent/requirements.txt' with dependencies.\n","output_type":"stream"}],"execution_count":16},{"id":"b4fec0c4","cell_type":"markdown","source":"### 8.3: Get Your Custom URL\n\nGet your custom URL to access the ADK web UI in the Kaggle Notebooks environment:","metadata":{}},{"id":"ab427af2","cell_type":"code","source":"url_prefix = get_adk_proxy_url()","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:03:13.654948Z","iopub.execute_input":"2025-11-30T22:03:13.655278Z","iopub.status.idle":"2025-11-30T22:03:13.663077Z","shell.execute_reply.started":"2025-11-30T22:03:13.655256Z","shell.execute_reply":"2025-11-30T22:03:13.662082Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n            </ol>\n            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n        </div>\n        <a href='https://kkb-production.jupyter-proxy.kaggle.net/k/282969130/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..pE8JqCFdrOMSC9IJFtKVmQ.uSmRbkcdFuyey4cwSN3l9ssXI7L3ZUGXbHo2w6dSYeKe2p_EbmV0DKX1dJNNPDUb9TrB9HFc5-YOPGj1Z5Z2IiPoOgqNEmeVYKnE6YZILcFR0jyPvDfu7Z8v0HZS1jSsYS8eQELPNcoJz7fGvPAN97jQGFcw_87ehgU5hwW8jb9QN5heLQ-1Se764G3o964YDXk6beafOYW4hAYHCoP5wg5aIm5Hkj53GFgFaPmyxEC09dRUuLqJvjL9hj6AjJEK.vCANzVxJVtCdxifIQTQ8_g/proxy/proxy/8000' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after running cell below) ‚Üó\n        </a>\n    </div>\n    "},"metadata":{}}],"execution_count":17},{"id":"1bcfb500","cell_type":"markdown","source":"### 8.4: Run ADK Web\n\nNow we can run ADK web:","metadata":{}},{"id":"0be83c11","cell_type":"code","source":"!adk web --url_prefix {url_prefix}","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:03:18.013006Z","iopub.execute_input":"2025-11-30T22:03:18.013377Z","iopub.status.idle":"2025-11-30T22:08:29.654577Z","shell.execute_reply.started":"2025-11-30T22:03:18.013351Z","shell.execute_reply":"2025-11-30T22:08:29.653612Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/google/adk/cli/fast_api.py:130: UserWarning: [EXPERIMENTAL] InMemoryCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  credential_service = InMemoryCredentialService()\n/usr/local/lib/python3.11/dist-packages/google/adk/auth/credential_service/in_memory_credential_service.py:33: UserWarning: [EXPERIMENTAL] BaseCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__()\n\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m96\u001b[0m]\n\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server started                                                      |\n|                                                                             |\n| For local testing, access at http://127.0.0.1:8000.                         |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application startup complete.\n\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[33m307 Temporary Redirect\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /dev-ui/ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /dev-ui/styles-EVMPSV3U.css HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /dev-ui/chunk-2WH2EVR6.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /dev-ui/main-OS2OH2S3.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET /dev-ui/polyfills-B6TNHZQ6.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /dev-ui/assets/config/runtime-config.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /dev-ui/adk_favicon.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /list-apps?relative_path=./ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /dev-ui/assets/ADK-512-color.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.adk_web_server:New session created: 4ff5bc0e-8787-4018-aca5-a01ac376a8f2\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mPOST /apps/research-agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /builder/app/research-agent?ts=1764540243196 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /apps/research-agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /apps/research-agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.utils.agent_loader:Found root_agent in research-agent.agent\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /debug/trace/bc942d2f-57ef-4603-8fd1-126e778897a0 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/bc942d2f-57ef-4603-8fd1-126e778897a0/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/bc942d2f-57ef-4603-8fd1-126e778897a0/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET /debug/trace/bc942d2f-57ef-4603-8fd1-126e778897a0 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/8d596ae3-5d4b-4aeb-a94e-5792e9276b21/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /debug/trace/8d596ae3-5d4b-4aeb-a94e-5792e9276b21 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /debug/trace/d56e643b-699f-4bd3-baf8-0fe06f5ec54a HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/d56e643b-699f-4bd3-baf8-0fe06f5ec54a/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /debug/trace/ae655265-1204-4ca8-83bf-ed93e83cba07 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/ae655265-1204-4ca8-83bf-ed93e83cba07/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /debug/trace/bc942d2f-57ef-4603-8fd1-126e778897a0 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/bc942d2f-57ef-4603-8fd1-126e778897a0/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /debug/trace/da27634d-ecf9-453c-a17e-17a813fbd5c7 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/da27634d-ecf9-453c-a17e-17a813fbd5c7/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/8d596ae3-5d4b-4aeb-a94e-5792e9276b21/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /debug/trace/8d596ae3-5d4b-4aeb-a94e-5792e9276b21 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /debug/trace/0983a01a-23c6-4112-81fd-afc088fbf4cf HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/0983a01a-23c6-4112-81fd-afc088fbf4cf/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /debug/trace/session/4ff5bc0e-8787-4018-aca5-a01ac376a8f2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /debug/trace/9f873ab6-0595-4118-bba0-c58c4966dd14 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/9f873ab6-0595-4118-bba0-c58c4966dd14/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.155:0 - \"\u001b[1mGET /debug/trace/9f873ab6-0595-4118-bba0-c58c4966dd14 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/9f873ab6-0595-4118-bba0-c58c4966dd14/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.156:0 - \"\u001b[1mGET /debug/trace/1a3c4f65-c7d9-4442-9cd7-b44cf521cd3c HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.154:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/1a3c4f65-c7d9-4442-9cd7-b44cf521cd3c/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.152:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/4ff5bc0e-8787-4018-aca5-a01ac376a8f2/events/1a3c4f65-c7d9-4442-9cd7-b44cf521cd3c/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.79.153:0 - \"\u001b[1mGET /debug/trace/1a3c4f65-c7d9-4442-9cd7-b44cf521cd3c HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n^C\n\u001b[32mINFO\u001b[0m:     Shutting down\n\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server shutting down...                                             |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m96\u001b[0m]\n\nAborted!\n","output_type":"stream"}],"execution_count":18},{"id":"9b0b324a","cell_type":"markdown","source":"### 8.5: Access the UI\n\nNow you can access the ADK web UI using the link above.\n\n‚ÄºÔ∏è **IMPORTANT: DO NOT SHARE THE PROXY LINK** with anyone - treat it as sensitive data as it contains your authentication token in the URL.\n\nOnce you open the link, you'll see the ADK web interface where you can interact with your research agent in a visual interface.","metadata":{}},{"id":"878702d5","cell_type":"markdown","source":"---\n\n## üìã Conclusion\n\nThis project demonstrates a production-ready **Academic Research Assistant Agent** that leverages:\n\n- **ArXiv API Integration**: Direct access to academic papers from ArXiv\n- **Multi-agent architecture**: Specialized agents for research, analysis, and formatting\n- **Custom tools**: ArXiv search, citation formatting, and persistent memory\n- **Session management**: Stateful conversations with context retention\n- **Observability**: Comprehensive logging for debugging and monitoring\n- **Production Deployment**: Ready for deployment to Vertex AI Agent Engine\n- **Scalability**: Cloud-native architecture for handling production workloads\n\n### Next Steps:\n\n1. **Enhance the Agent**: Add more academic databases (PubMed, IEEE, Semantic Scholar)\n2. **Deploy to Production**: Follow Section 6 to deploy on Vertex AI Agent Engine\n3. **Monitor & Improve**: Use Vertex AI's monitoring tools to track performance\n4. **Scale**: Configure auto-scaling based on usage patterns\n\n### Useful Resources:\n\n- [Vertex AI Agent Engine Documentation](https://docs.cloud.google.com/agent-builder/agent-engine/overview)\n- [ArXiv API Guide](https://info.arxiv.org/help/api/index.html)\n- [Google ADK Documentation](https://google.github.io/adk-docs/)\n\nThis agent is now ready for academic researchers to discover, analyze, and cite relevant papers efficiently!","metadata":{}}]}
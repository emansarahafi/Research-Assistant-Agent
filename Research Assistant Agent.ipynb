{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/emanafi/research-assistant-agent?scriptVersionId=282969130\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Capstone Project: Advanced Research Assistant Agent\n\n**Track:** Freestyle / Agents for Good (Education/Research)\n\n**Objective:** Build a comprehensive AI agent system that helps researchers by:\n1.  Searching for papers on multiple sub-topics in **parallel**.\n2.  **Analyzing** the findings (e.g., plotting publication trends) using code execution.\n3.  **Formatting** citations.\n4.  **Saving** interesting findings to a persistent \"Long-Term Memory\".\n\n**Key Concepts Applied:**\n\n1.  **Multi-agent system**:\n    *   **Parallel agents**: We implement a `parallel_research` tool that spawns multiple search tasks simultaneously.\n    *   **Sequential agents**: The workflow moves from Research -> Analysis -> Formatting.\n    *   **Agent powered by an LLM**: All agents use Gemini.\n\n2.  **Tools**:\n    *   **Built-in tools**: `google_search` and `code_execution`.\n    *   **Custom tools**: `format_citation`, `save_to_memory`, `parallel_research`.\n\n3.  **Sessions & Memory**:\n    *   **Sessions**: `InMemorySessionService` for conversation context.\n    *   **Long-term memory**: A file-based JSON store (`knowledge_base.json`) to persist data across sessions.\n\n4.  **Observability**:\n    *   **Logging**: Detailed logging of tool usage and agent steps.\n\n5.  **Agent evaluation**:\n    *   Automated checks for output quality.\n\n6.  **Agent deployment**:\n    *   **Deployment**: We demonstrate how to wrap the agent in a Vertex AI Agent Engine & a Flask API for deployment as a web service.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è 1. Setup and Configuration\n\nFirst, we install the necessary dependencies and configure the API key.\n\n### 1.1: Install ADK","metadata":{}},{"cell_type":"code","source":"# Install the Agent Development Kit (ADK), ArXiv and AsyncIO\n!pip install google-adk arxiv nest-asyncio\n\nprint(\"‚úÖ ADK, ArXiv, and nest-asyncio installed successfully.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:58:32.253375Z","iopub.execute_input":"2025-11-30T21:58:32.253715Z","iopub.status.idle":"2025-11-30T21:58:43.369598Z","shell.execute_reply.started":"2025-11-30T21:58:32.253689Z","shell.execute_reply":"2025-11-30T21:58:43.368636Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.2: Configure API Key","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:58:47.332035Z","iopub.execute_input":"2025-11-30T21:58:47.332378Z","iopub.status.idle":"2025-11-30T21:58:47.501263Z","shell.execute_reply.started":"2025-11-30T21:58:47.332349Z","shell.execute_reply":"2025-11-30T21:58:47.500271Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.3: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"from google.genai import types\n\nretry_config = types.HttpRetryOptions(\n    attempts=3,\n    exp_base=2,\n    initial_delay=1,\n    http_status_codes=[429, 500, 503],\n)\n\nprint(\"‚úÖ Retry configuration set.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:58:50.036159Z","iopub.execute_input":"2025-11-30T21:58:50.036473Z","iopub.status.idle":"2025-11-30T21:58:54.430865Z","shell.execute_reply.started":"2025-11-30T21:58:50.036448Z","shell.execute_reply":"2025-11-30T21:58:54.429849Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üõ†Ô∏è 2. Define Tools (Built-in & Custom)\n\nWe define a set of tools to empower our agents:\n1.  **`format_citation`**: Formats paper details.\n2.  **`save_to_memory`**: Persists data to a JSON file (Long-Term Memory).\n3.  **`parallel_research`**: Simulates parallel agent execution for broader search coverage.\n\n### 2.1: Import ADK Components","metadata":{}},{"cell_type":"code","source":"import json\nimport logging\nimport asyncio\nfrom typing import List, Dict, Any\nfrom google.genai.types import Content, Part\n\n# ADK Imports\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import google_search, AgentTool\nfrom google.adk.code_executors import BuiltInCodeExecutor\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:58:59.657307Z","iopub.execute_input":"2025-11-30T21:58:59.658295Z","iopub.status.idle":"2025-11-30T21:59:44.424274Z","shell.execute_reply.started":"2025-11-30T21:58:59.65826Z","shell.execute_reply":"2025-11-30T21:59:44.423244Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.2: Configure Logging for Observability\n\nSet up logging to track agent operations and tool usage throughout the application.","metadata":{}},{"cell_type":"code","source":"# Configure Logging for Observability\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\nprint(\"‚úÖ Logging configured.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:59:49.872732Z","iopub.execute_input":"2025-11-30T21:59:49.874034Z","iopub.status.idle":"2025-11-30T21:59:49.880151Z","shell.execute_reply.started":"2025-11-30T21:59:49.873992Z","shell.execute_reply":"2025-11-30T21:59:49.879293Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.3: Helper Functions for ADK Web UI\n\nHelper functions for accessing the ADK web interface in the Kaggle Notebooks environment.","metadata":{}},{"cell_type":"code","source":"from IPython.core.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n# Gets the proxied URL in the Kaggle Notebooks environment\ndef get_adk_proxy_url():\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0]['base_url']\n\n    try:\n        path_parts = baseURL.split('/')\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n            </ol>\n            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after running cell below) ‚Üó\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n\n    return url_prefix\n\nprint(\"‚úÖ Helper functions defined.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:59:52.337179Z","iopub.execute_input":"2025-11-30T21:59:52.337534Z","iopub.status.idle":"2025-11-30T21:59:52.518253Z","shell.execute_reply.started":"2025-11-30T21:59:52.337483Z","shell.execute_reply":"2025-11-30T21:59:52.517362Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.4: Define Custom Tools","metadata":{}},{"cell_type":"code","source":"import arxiv\nimport time\n\n# --- ArXiv API Tool ---\ndef search_arxiv(query: str, max_results: int = 5) -> str:\n    \"\"\"\n    Searches ArXiv for research papers matching the query.\n    Includes retry logic and uses the updated Client API to avoid deprecation warnings.\n    \n    Args:\n        query: Search query for papers\n        max_results: Maximum number of results to return (default: 5)\n        \n    Returns:\n        Formatted string with paper details\n    \"\"\"\n    client = arxiv.Client()\n    \n    search = arxiv.Search(\n        query=query,\n        max_results=max_results,\n        sort_by=arxiv.SortCriterion.SubmittedDate\n    )\n    \n    results = []\n    try:\n        # Use client.results() instead of search.results() to fix deprecation warning\n        # and add retry logic for robustness\n        for attempt in range(3):\n            try:\n                # Convert generator to list to ensure we actually fetch data\n                found_papers = list(client.results(search))\n                break\n            except Exception as e:\n                if attempt == 2: # Last attempt\n                    raise e\n                time.sleep(1) # Wait 1s before retry\n        \n        for paper in found_papers:\n            result = {\n                \"title\": paper.title,\n                \"authors\": [author.name for author in paper.authors],\n                \"summary\": paper.summary[:300] + \"...\" if len(paper.summary) > 300 else paper.summary,\n                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n                \"url\": paper.entry_id,\n                \"pdf_url\": paper.pdf_url\n            }\n            results.append(result)\n            \n        if not results:\n            return f\"No papers found for query: {query}\"\n            \n        # Format results\n        formatted = f\"Found {len(results)} papers for '{query}':\\n\\n\"\n        for i, paper in enumerate(results, 1):\n            authors = \", \".join(paper[\"authors\"][:3])\n            if len(paper[\"authors\"]) > 3:\n                authors += \" et al.\"\n            formatted += f\"{i}. **{paper['title']}**\\n\"\n            formatted += f\"   Authors: {authors}\\n\"\n            formatted += f\"   Published: {paper['published']}\\n\"\n            formatted += f\"   URL: {paper['url']}\\n\"\n            formatted += f\"   Summary: {paper['summary']}\\n\\n\"\n            \n        logger.info(f\"ArXiv search completed: {len(results)} results for '{query}'\")\n        return formatted\n        \n    except Exception as e:\n        error_msg = f\"ArXiv search failed: {str(e)}\"\n        logger.error(error_msg)\n        return f\"Error searching ArXiv: {str(e)}\"\n\nprint(\"‚úÖ ArXiv search tool defined (updated with Client API and retries).\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T21:59:55.811834Z","iopub.execute_input":"2025-11-30T21:59:55.812451Z","iopub.status.idle":"2025-11-30T21:59:55.863094Z","shell.execute_reply.started":"2025-11-30T21:59:55.812426Z","shell.execute_reply":"2025-11-30T21:59:55.862239Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Custom Tool 1: Citation Formatter ---\ndef format_citation(title: str, authors: List[str], year: str, url: str) -> str:\n    \"\"\"Formats a research paper citation.\"\"\"\n    author_str = \", \".join(authors)\n    citation = f\"{author_str} ({year}). **{title}**. Retrieved from {url}\"\n    logger.info(f\"Formatted citation for: {title}\")\n    return citation\n\n# --- Custom Tool 2: Long-Term Memory (File-based) ---\nMEMORY_FILE = \"knowledge_base.json\"\n\ndef save_to_memory(key: str, value: Any) -> str:\n    \"\"\"Saves a key-value pair to a persistent JSON file.\"\"\"\n    try:\n        if os.path.exists(MEMORY_FILE):\n            with open(MEMORY_FILE, 'r') as f:\n                data = json.load(f)\n        else:\n            data = {}\n            \n        data[key] = value\n        \n        with open(MEMORY_FILE, 'w') as f:\n            json.dump(data, f, indent=2)\n            \n        logger.info(f\"Saved to memory: {key}\")\n        return f\"Successfully saved '{key}' to long-term memory.\"\n    except Exception as e:\n        return f\"Error saving to memory: {str(e)}\"\n\n# --- Custom Tool 3: Parallel Research Orchestrator ---\n# Note: In a real scenario, this would spawn independent agent processes.\n# Here, we simulate it by running multiple google searches concurrently.\n\nasync def parallel_research(topics: List[str]) -> List[str]:\n    \"\"\"\n    Performs research on multiple topics simultaneously.\n    Args:\n        topics: A list of sub-topics to research.\n    Returns:\n        A combined list of search results for all topics.\n    \"\"\"\n    logger.info(f\"Starting parallel research on: {topics}\")\n    \n    # Define a helper for a single search\n    async def search_topic(topic):\n        # We use the google_search tool directly here for simulation\n        # In a full ADK app, this could be `await researcher_agent.run(topic)`\n        logger.info(f\"Searching for: {topic}\")\n        return google_search(topic)\n\n    # Run searches in parallel\n    results = await asyncio.gather(*(search_topic(topic) for topic in topics))\n    \n    # Combine results\n    combined_results = []\n    for topic, result in zip(topics, results):\n        combined_results.append(f\"--- Results for '{topic}' ---\\n{result}\\n\")\n        \n    return combined_results\n\nprint(\"‚úÖ Custom tools defined: format_citation, save_to_memory, parallel_research.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:00:03.167842Z","iopub.execute_input":"2025-11-30T22:00:03.168227Z","iopub.status.idle":"2025-11-30T22:00:03.178427Z","shell.execute_reply.started":"2025-11-30T22:00:03.168202Z","shell.execute_reply":"2025-11-30T22:00:03.177476Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ü§ñ 3. Define Agents\n\nWe define a robust multi-agent system:\n1.  **`researcher_agent`**: Uses `parallel_research` to gather broad information.\n2.  **`analyst_agent`**: Uses `BuiltInCodeExecutor` to analyze data (e.g., calculate stats, plot trends).\n3.  **`formatter_agent`**: Formats citations.\n4.  **`root_agent`**: Orchestrates the entire pipeline.","metadata":{}},{"cell_type":"code","source":"# 1. Researcher Agent (Parallel Capabilities with ArXiv)\nresearcher_agent = LlmAgent(\n    name=\"researcher_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    description=\"Searches for research papers using ArXiv API.\",\n    instruction=\"\"\"\n    You are a research assistant with access to ArXiv.\n    When given a research topic:\n    1. Use the 'search_arxiv' tool to find relevant academic papers.\n    2. Focus on recent papers (2023-2025 when possible).\n    3. Return the paper details including titles, authors, dates, and URLs.\n    \"\"\",\n    tools=[search_arxiv]\n)\n\n# 2. Analyst Agent (Manual Analysis)\nanalyst_agent = LlmAgent(\n    name=\"analyst_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    description=\"Analyzes research data and creates visualizations.\",\n    instruction=\"\"\"\n    You are a data analyst.\n    Given a list of research papers or search results:\n    1. Extract the publication years from the paper information.\n    2. Calculate the distribution of papers by year.\n    3. Create a simple ASCII bar chart showing the distribution.\n    4. Return the analysis summary and the ASCII chart.\n    \n    Example ASCII chart format:\n    2025: *** (3 papers)\n    2024: ***** (5 papers)\n    2023: ** (2 papers)\n    \"\"\"\n)\n\n# 3. Formatter Agent\nformatter_agent = LlmAgent(\n    name=\"formatter_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    description=\"Formats paper details into proper citations.\",\n    instruction=\"\"\"\n    You are a citation expert. \n    Take the raw paper information and format it into clean academic citations.\n    Use APA format: Authors (Year). Title. Retrieved from URL\n    Return the final list of formatted citations as a numbered list.\n    \"\"\"\n)\n\n# 4. Root Agent (Orchestrator & Memory Manager)\nroot_agent = LlmAgent(\n    name=\"root_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    instruction=\"\"\"\n    You are the Lead Research Coordinator.\n    \n    Your workflow is:\n    1. **Research**: Delegate to 'researcher_agent' to find papers on the user's topic.\n    2. **Analyze**: Delegate the findings to 'analyst_agent' to get a distribution of publication years.\n    3. **Format**: Delegate to 'formatter_agent' to get a list of citations.\n    4. **Save**: Use the 'save_to_memory' tool to save the final citation list and analysis to the 'knowledge_base.json' file. Use the topic as the key.\n    5. **Report**: YOU MUST PRINT the final report to the user.\n       - Show the \"Formatted Citations\" list.\n       - Show the \"Publication Year Analysis\" chart.\n       - Confirm that data has been saved to memory.\n       \n    CRITICAL: Do NOT stop after calling tools. You MUST generate a final text response summarizing the results.\n    \"\"\",\n    tools=[\n        AgentTool(agent=researcher_agent), \n        AgentTool(agent=analyst_agent), \n        AgentTool(agent=formatter_agent),\n        save_to_memory\n    ]\n)\n\nprint(\"‚úÖ Agents defined: Researcher, Analyst, Formatter, and Root.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:00:07.848254Z","iopub.execute_input":"2025-11-30T22:00:07.84914Z","iopub.status.idle":"2025-11-30T22:00:07.857842Z","shell.execute_reply.started":"2025-11-30T22:00:07.849106Z","shell.execute_reply":"2025-11-30T22:00:07.856826Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚öñÔ∏è 4. Evaluation Logic\n\nWe define an evaluation function to check if the agent's response meets our requirements (contains a list, recent years, and URLs). We will use this during the agent execution.","metadata":{}},{"cell_type":"code","source":"def evaluate_response(response_text: str):\n    \"\"\"\n    Evaluation to check if the response contains citations, analysis, and confirms saving.\n    \"\"\"\n    score = 0\n    checks = []\n    \n    # Check 1: List format (Citations)\n    if \"1.\" in response_text or \"-\" in response_text:\n        score += 1\n        checks.append(\"List format detected\")\n    \n    # Check 2: Recent years\n    if \"2024\" in response_text or \"2025\" in response_text:\n        score += 1\n        checks.append(\"Recent years detected\")\n        \n    # Check 3: URLs\n    if \"http\" in response_text:\n        score += 1\n        checks.append(\"URLs detected\")\n\n    # Check 4: Analysis/Chart\n    if \"Analysis\" in response_text or \"|\" in response_text or \"*\" in response_text: # Simple check for ASCII chart chars\n        score += 1\n        checks.append(\"Analysis/Chart detected\")\n\n    # Check 5: Memory Save\n    if \"saved\" in response_text.lower() or \"memory\" in response_text.lower():\n        score += 1\n        checks.append(\"Memory save confirmed\")\n        \n    print(f\"\\n--- Evaluation Results ---\")\n    print(f\"Score: {score}/5\")\n    print(f\"Checks passed: {', '.join(checks)}\")\n    \nprint(\"‚úÖ Evaluation function defined.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:00:13.609412Z","iopub.execute_input":"2025-11-30T22:00:13.610119Z","iopub.status.idle":"2025-11-30T22:00:13.617354Z","shell.execute_reply.started":"2025-11-30T22:00:13.610092Z","shell.execute_reply":"2025-11-30T22:00:13.616343Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚ñ∂Ô∏è 5. Run the Agent\n\nNow we can interact with our agent. The `run_agent` function handles session management automatically, creating a fresh session for each query to ensure reliability in notebook environments.","metadata":{}},{"cell_type":"code","source":"# Initialize Session Service and Runner\nfrom google.adk.runners import Runner\nimport nest_asyncio\nimport traceback\nimport logging\n\n# Apply nest_asyncio to allow nested event loops (critical for notebook environments)\nnest_asyncio.apply()\n\n# Suppress the specific google_genai warning about non-text parts\nlogging.getLogger(\"google_genai.types\").setLevel(logging.ERROR)\n\nAPP_NAME = \"research_agent\"\nUSER_ID = \"researcher_01\"\n\nsession_service = InMemorySessionService()\nrunner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n\nprint(\"‚úÖ Session service and runner initialized.\")\nprint(f\"   - Application: {APP_NAME}\")\nprint(f\"   - User: {USER_ID}\")\nprint(f\"   - Using: {session_service.__class__.__name__}\")\n\nasync def run_agent(query: str, session_id: str = \"default_session\"):\n    \"\"\"\n    Runs the agent with the given query and returns the full response.\n    Includes debug logging to trace execution flow and errors.\n    \"\"\"\n    print(f\"User > {query}\")\n    print(\"-\" * 50)\n    \n    # Create or get the session\n    try:\n        session = await session_service.create_session(\n            app_name=APP_NAME, \n            user_id=USER_ID, \n            session_id=session_id\n        )\n    except:\n        session = await session_service.get_session(\n            app_name=APP_NAME, \n            user_id=USER_ID, \n            session_id=session_id\n        )\n    \n    full_response = \"\"\n    \n    # Create a Content object from the query string\n    message = Content(parts=[Part(text=query)], role=\"user\")\n    \n    event_count = 0\n    try:\n        # Run the agent asynchronously with the session\n        async for event in runner.run_async(\n            user_id=USER_ID, \n            session_id=session.id,\n            new_message=message\n        ):\n            event_count += 1\n            \n            # Check for content parts\n            if event.content and event.content.parts:\n                for part in event.content.parts:\n                    # Handle text parts\n                    if part.text and part.text != \"None\":\n                        print(f\"Agent > {part.text}\")\n                        full_response += part.text + \"\\n\"\n                    \n                    # Handle function calls\n                    if part.function_call:\n                        print(f\"ü§ñ Agent is calling tool: {part.function_call.name}\")\n            \n            # Log errors if present in the event\n            if hasattr(event, 'error') and event.error:\n                print(f\"‚ö†Ô∏è Event Error: {event.error}\")\n                \n    except Exception as e:\n        print(f\"‚ùå Error during agent execution: {str(e)}\")\n        traceback.print_exc()\n        \n    if event_count == 0:\n        print(\"‚ö†Ô∏è Warning: No events received from the agent. Check network connection and API keys.\")\n    elif not full_response.strip():\n        print(\"‚ö†Ô∏è Warning: Agent executed tools but returned no final text response.\")\n        print(\"   This usually means the agent loop finished before the final answer was generated.\")\n        print(\"   Try running the cell again, or check if the 'Root Agent' instructions are clear.\")\n                \n    return full_response\n\n# Example Query - ArXiv Search\nquery = \"Agentic AI Design Patterns\"\n\n# Run the query and evaluate\ntry:\n    response = await run_agent(query)\n    if response.strip():\n        evaluate_response(response)\n    else:\n        print(\"No response received to evaluate.\")\nexcept Exception as e:\n    print(f\"Failed to run agent: {e}\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:00:20.404218Z","iopub.execute_input":"2025-11-30T22:00:20.404555Z","iopub.status.idle":"2025-11-30T22:01:00.542038Z","shell.execute_reply.started":"2025-11-30T22:00:20.404524Z","shell.execute_reply":"2025-11-30T22:01:00.540877Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üöÄ 6. Deploy to Vertex AI Agent Engine\n\nVertex AI Agent Engine allows you to deploy and scale your AI agents in production. Here's how to prepare and deploy your agent.\n\n### 6.1: Install Vertex AI SDK","metadata":{}},{"cell_type":"code","source":"!pip install google-cloud-aiplatform\n\nprint(\"‚úÖ Vertex AI SDK installed.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6.2: Configure Google Cloud Project\n\nSet up your Google Cloud project credentials for Vertex AI deployment.","metadata":{}},{"cell_type":"code","source":"from google.cloud import aiplatform\n\n# Configure your Google Cloud project\nPROJECT_ID = \"your-project-id\"  # Replace with your GCP project ID\nLOCATION = \"us-central1\"  # Choose your preferred region\nSTAGING_BUCKET = \"gs://your-bucket-name\"  # Replace with your GCS bucket\n\n# Initialize Vertex AI\naiplatform.init(\n    project=PROJECT_ID,\n    location=LOCATION,\n    staging_bucket=STAGING_BUCKET\n)\n\nprint(f\"‚úÖ Vertex AI initialized for project: {PROJECT_ID}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6.3: Create Agent Package (Multi-Agent)\n\nCreate the agent files needed for deployment. We will package our full **Multi-Agent System** (Researcher, Analyst, Formatter, Root) into the `agent.py` file.","metadata":{}},{"cell_type":"code","source":"import os\n\n# Create deployment directory\nos.makedirs(\"vertex_agent_deployment\", exist_ok=True)\n\n# Create agent.py - Main agent file\nagent_code = \"\"\"\nimport arxiv\nimport json\nimport os\nimport logging\nfrom typing import List, Any\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.tools import AgentTool\nfrom google.genai import types\n\n# Configure Logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# --- Tools ---\n\ndef search_arxiv(query: str, max_results: int = 5) -> str:\n    \\\"\\\"\\\"Searches ArXiv for research papers matching the query.\\\"\\\"\\\"\n    try:\n        search = arxiv.Search(\n            query=query,\n            max_results=max_results,\n            sort_by=arxiv.SortCriterion.SubmittedDate\n        )\n        \n        results = []\n        for paper in search.results():\n            result = {\n                \"title\": paper.title,\n                \"authors\": [author.name for author in paper.authors],\n                \"summary\": paper.summary[:300] + \"...\" if len(paper.summary) > 300 else paper.summary,\n                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n                \"url\": paper.entry_id,\n            }\n            results.append(result)\n            \n        if not results:\n            return f\"No papers found for query: {query}\"\n\n        formatted = f\"Found {len(results)} papers for '{query}':\\\\n\\\\n\"\n        for i, paper in enumerate(results, 1):\n            authors = \", \".join(paper[\"authors\"][:3])\n            if len(paper[\"authors\"]) > 3:\n                authors += \" et al.\"\n            formatted += f\"{i}. **{paper['title']}**\\\\n\"\n            formatted += f\"   Authors: {authors}\\\\n\"\n            formatted += f\"   Published: {paper['published']}\\\\n\"\n            formatted += f\"   URL: {paper['url']}\\\\n\"\n            formatted += f\"   Summary: {paper['summary']}\\\\n\\\\n\"\n        return formatted\n    except Exception as e:\n        return f\"Error searching ArXiv: {str(e)}\"\n\ndef format_citation(title: str, authors: List[str], year: str, url: str) -> str:\n    \\\"\\\"\\\"Formats a research paper citation.\\\"\\\"\\\"\n    author_str = \", \".join(authors)\n    return f\"{author_str} ({year}). **{title}**. Retrieved from {url}\"\n\n# Use /tmp for writable location in cloud environments\nMEMORY_FILE = \"/tmp/knowledge_base.json\"\n\ndef save_to_memory(key: str, value: Any) -> str:\n    \\\"\\\"\\\"Saves a key-value pair to a persistent JSON file.\\\"\\\"\\\"\n    try:\n        if os.path.exists(MEMORY_FILE):\n            with open(MEMORY_FILE, 'r') as f:\n                data = json.load(f)\n        else:\n            data = {}\n            \n        data[key] = value\n        \n        with open(MEMORY_FILE, 'w') as f:\n            json.dump(data, f, indent=2)\n            \n        return f\"Successfully saved '{key}' to long-term memory.\"\n    except Exception as e:\n        return f\"Error saving to memory: {str(e)}\"\n\n# --- Agents ---\n\nretry_config = types.HttpRetryOptions(\n    attempts=3,\n    exp_base=2,\n    initial_delay=1,\n    http_status_codes=[429, 500, 503],\n)\n\n# Shared Model\nmodel = Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config)\n\n# 1. Researcher Agent\nresearcher_agent = LlmAgent(\n    name=\"researcher_agent\",\n    model=model,\n    description=\"Searches for research papers using ArXiv API.\",\n    instruction='''\n    You are a research assistant with access to ArXiv.\n    When given a research topic:\n    1. Use the 'search_arxiv' tool to find relevant academic papers.\n    2. Focus on recent papers (2023-2025 when possible).\n    3. Return the paper details including titles, authors, dates, and URLs.\n    ''',\n    tools=[search_arxiv]\n)\n\n# 2. Analyst Agent\nanalyst_agent = LlmAgent(\n    name=\"analyst_agent\",\n    model=model,\n    description=\"Analyzes research data and creates visualizations.\",\n    instruction='''\n    You are a data analyst.\n    Given a list of research papers or search results:\n    1. Extract the publication years from the paper information.\n    2. Calculate the distribution of papers by year.\n    3. Create a simple ASCII bar chart showing the distribution.\n    4. Return the analysis summary and the ASCII chart.\n    '''\n)\n\n# 3. Formatter Agent\nformatter_agent = LlmAgent(\n    name=\"formatter_agent\",\n    model=model,\n    description=\"Formats paper details into proper citations.\",\n    instruction='''\n    You are a citation expert. \n    Take the raw paper information and format it into clean academic citations.\n    Use APA format: Authors (Year). Title. Retrieved from URL\n    Return the final list of formatted citations as a numbered list.\n    '''\n)\n\n# 4. Root Agent (Orchestrator)\nroot_agent = LlmAgent(\n    name=\"root_agent\",\n    model=model,\n    instruction='''\n    You are the Lead Research Coordinator.\n    \n    Your workflow is:\n    1. **Research**: Delegate to 'researcher_agent' to find papers on the user's topic.\n    2. **Analyze**: Delegate the findings to 'analyst_agent' to get a distribution of publication years.\n    3. **Format**: Delegate to 'formatter_agent' to get a list of citations.\n    4. **Save**: Use the 'save_to_memory' tool to save the final citation list and analysis to the 'knowledge_base.json' file. Use the topic as the key.\n    5. **Report**: YOU MUST PRINT the final report to the user.\n       - Show the \"Formatted Citations\" list.\n       - Show the \"Publication Year Analysis\" chart.\n       - Confirm that data has been saved to memory.\n       \n    CRITICAL: Do NOT stop after calling tools. You MUST generate a final text response summarizing the results.\n    ''',\n    tools=[\n        AgentTool(agent=researcher_agent), \n        AgentTool(agent=analyst_agent), \n        AgentTool(agent=formatter_agent),\n        save_to_memory\n    ]\n)\n\n# Export the root agent\nagent = root_agent\n\"\"\"\n\nwith open(\"vertex_agent_deployment/agent.py\", \"w\") as f:\n    f.write(agent_code)\n\n# Create requirements.txt\nrequirements = \"\"\"google-adk\narxiv\ngoogle-cloud-aiplatform\n\"\"\"\n\nwith open(\"vertex_agent_deployment/requirements.txt\", \"w\") as f:\n    f.write(requirements)\n\n# Create deployment config\nconfig = \"\"\"{\n  \"agent_name\": \"research-assistant\",\n  \"agent_description\": \"Multi-agent academic research system\",\n  \"model\": \"gemini-2.5-flash-lite\"\n}\n\"\"\"\n\nwith open(\"vertex_agent_deployment/config.json\", \"w\") as f:\n    f.write(config)\n\nprint(\"‚úÖ Agent package created in 'vertex_agent_deployment/' directory\")\nprint(\"   - agent.py: Multi-agent system code\")\nprint(\"   - requirements.txt: Dependencies\")\nprint(\"   - config.json: Deployment configuration\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6.4: Deploy to Vertex AI Agent Engine\n\nNow that the agent package is created in the `vertex_agent_deployment/` directory, you can deploy it to Vertex AI.\n\nYou can use the Google Cloud CLI (`gcloud`) to deploy your agent. Run the following command in your terminal (ensure you have authenticated with `gcloud auth login`):\n\n```bash\ngcloud beta ai agents create \\\n  --display-name=\"Research Assistant\" \\\n  --project=$PROJECT_ID \\\n  --location=$LOCATION \\\n  --agent-package-path=\"vertex_agent_deployment/\"\n```\n\nAlternatively, you can zip the folder and upload it via the Google Cloud Console.","metadata":{}},{"cell_type":"markdown","source":"### 6.5: Test Deployed Agent\n\nOnce deployed, you can interact with your agent via the Vertex AI API.","metadata":{}},{"cell_type":"code","source":"# Example: Interacting with deployed agent\ntest_code = '''\nfrom google.cloud import aiplatform\nfrom google.genai.types import Content, Part\n\n# Initialize the agent client\nAGENT_ID = \"your-agent-id\"  # Replace with your deployed agent ID\n\n# Create a prediction request\ndef query_deployed_agent(query: str):\n    \"\"\"Query the deployed Vertex AI agent.\"\"\"\n    \n    endpoint = aiplatform.Endpoint(\n        endpoint_name=f\"projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{AGENT_ID}\"\n    )\n    \n    # Format the request\n    message = Content(parts=[Part(text=query)], role=\"user\")\n    \n    # Send request\n    response = endpoint.predict(instances=[{\"message\": message}])\n    \n    return response.predictions[0]\n\n# Test the deployed agent\ntry:\n    result = query_deployed_agent(\"Search for papers on transformers in NLP\")\n    print(\"Agent Response:\", result)\nexcept Exception as e:\n    print(f\"Note: Replace AGENT_ID and ensure agent is deployed. Error: {e}\")\n'''\n\nprint(\"üí¨ Example code to query your deployed agent:\")\nprint(test_code)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"REST API Example:\")\nprint(\"=\"*60)\n\nrest_example = f'''\ncurl -X POST \\\\\n  https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/agents/AGENT_ID:query \\\\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -d '{{\n    \"message\": \"Search for papers on quantum computing\",\n    \"session_id\": \"unique-session-id\"\n  }}'\n'''\n\nprint(rest_example)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîß 7. Alternative Deployment: Flask API (Local Testing)\n\nFor local testing and development, you can wrap the agent in a **Flask** application. This is useful for testing before deploying to Vertex AI.\n\n*Note: This is for local development only. Use Vertex AI Agent Engine for production deployments.*\n\n### 7.1: Create Flask API Server","metadata":{}},{"cell_type":"code","source":"from flask import Flask, request, jsonify\nimport threading\nfrom IPython.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\nimport nest_asyncio\nimport asyncio\n\n# Apply nest_asyncio to allow nested event loops\nnest_asyncio.apply()\n\n# Capture the main event loop where the runner was initialized\ntry:\n    MAIN_LOOP = asyncio.get_running_loop()\nexcept RuntimeError:\n    MAIN_LOOP = asyncio.new_event_loop()\n    asyncio.set_event_loop(MAIN_LOOP)\n\n# Define the Flask App\napp = Flask(__name__)\n\ndef run_agent_sync(query: str, session_id: str):\n    \"\"\"\n    Synchronous wrapper that runs the async agent on the main event loop.\n    This avoids 'attached to a different loop' errors by ensuring the runner\n    executes in the same loop where it was created.\n    \"\"\"\n    from google.genai.types import Content, Part\n    \n    async def run_agent_task():\n        # Create or get session\n        try:\n            session = await session_service.create_session(\n                app_name=APP_NAME, \n                user_id=USER_ID, \n                session_id=session_id\n            )\n        except:\n            session = await session_service.get_session(\n                app_name=APP_NAME, \n                user_id=USER_ID, \n                session_id=session_id\n            )\n        \n        full_response = \"\"\n        message = Content(parts=[Part(text=query)], role=\"user\")\n        \n        # Run the agent\n        async for event in runner.run_async(\n            user_id=USER_ID, \n            session_id=session.id,\n            new_message=message\n        ):\n            if event.content and event.content.parts:\n                part = event.content.parts[0]\n                if part.text and part.text != \"None\":\n                    print(f\"Agent > {part.text}\")\n                    full_response += part.text + \"\\n\"\n        \n        return full_response\n    \n    # Submit the task to the main loop from the Flask thread\n    future = asyncio.run_coroutine_threadsafe(run_agent_task(), MAIN_LOOP)\n    return future.result()\n\n@app.route('/chat', methods=['POST'])\ndef chat_endpoint():\n    \"\"\"\n    API Endpoint to interact with the Research Agent.\n    Expected JSON: {\"query\": \"your research topic\", \"session_id\": \"optional_session_id\"}\n    \"\"\"\n    data = request.json\n    query = data.get('query')\n    session_id = data.get('session_id', 'default_session')\n    \n    if not query:\n        return jsonify({\"error\": \"No query provided\"}), 400\n    \n    print(f\"API Request: {query}\")\n    \n    # Run the agent\n    try:\n        response_text = run_agent_sync(query, session_id)\n        return jsonify({\"response\": response_text, \"status\": \"success\"})\n    except Exception as e:\n        import traceback\n        error_details = traceback.format_exc()\n        print(f\"Error details: {error_details}\")\n        return jsonify({\"error\": str(e), \"status\": \"failed\"}), 500\n\n@app.route('/health', methods=['GET'])\ndef health_check():\n    \"\"\"Health check endpoint\"\"\"\n    return jsonify({\"status\": \"healthy\", \"agent\": \"Research Assistant\"})\n\ndef run_flask():\n    \"\"\"Runs the Flask app on port 5003.\"\"\"\n    app.run(host='0.0.0.0', port=5003, debug=False, use_reloader=False)\n\ndef get_flask_proxy_url():\n    \"\"\"Get the Kaggle proxy URL for Flask\"\"\"\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    FLASK_PORT = \"5003\"\n    \n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n    \n    baseURL = servers[0]['base_url']\n    \n    try:\n        path_parts = baseURL.split('/')\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n    \n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{FLASK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n    \n    styled_html = f\"\"\"\n    <div style=\"padding: 20px; border: 2px solid #4CAF50; border-radius: 8px; background-color: #f0fdf4; margin: 20px 0;\">\n        <h3 style=\"color: #2e7d32; margin-top: 0;\">üöÄ Flask API Running!</h3>\n        <p style=\"font-family: sans-serif; color: #333;\">Your Research Assistant API is now accessible.</p>\n        \n        <div style=\"background-color: white; padding: 15px; border-radius: 5px; margin: 15px 0;\">\n            <strong>Endpoints:</strong><br>\n            <code style=\"background-color: #f5f5f5; padding: 2px 6px; border-radius: 3px;\">POST {url}/chat</code> - Query the agent<br>\n            <code style=\"background-color: #f5f5f5; padding: 2px 6px; border-radius: 3px;\">GET {url}/health</code> - Health check\n        </div>\n        \n        <div style=\"background-color: #fff3cd; padding: 15px; border-radius: 5px; margin: 15px 0; border-left: 4px solid #ffc107;\">\n            <strong>Example cURL command:</strong><br>\n            <code style=\"display: block; margin-top: 10px; padding: 10px; background-color: #2d2d2d; color: #f8f8f2; border-radius: 3px; overflow-x: auto;\">\ncurl -X POST \"{url}/chat\" \\\\<br>\n  -H \"Content-Type: application/json\" \\\\<br>\n  -d '{{\"query\": \"Search for papers on quantum computing\"}}'\n            </code>\n        </div>\n        \n        <a href='{url}/health' target='_blank' style=\"\n            display: inline-block; background-color: #4CAF50; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease; margin-top: 10px;\">\n            Test Health Check ‚Üó\n        </a>\n    </div>\n    \"\"\"\n    \n    display(HTML(styled_html))\n    return url\n\n# Start Flask in background\nflask_thread = threading.Thread(target=run_flask, daemon=True)\nflask_thread.start()\n\nprint(\"‚úÖ Flask API server starting...\")\nprint(\"Run the next cell to get your API URL!\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:01:36.00092Z","iopub.execute_input":"2025-11-30T22:01:36.001236Z","iopub.status.idle":"2025-11-30T22:01:36.37156Z","shell.execute_reply.started":"2025-11-30T22:01:36.001215Z","shell.execute_reply":"2025-11-30T22:01:36.368425Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n### 7.2: Get Your Flask API URL\n\nGet your custom URL to access the Flask API in the Kaggle Notebooks environment:","metadata":{}},{"cell_type":"code","source":"# Get and display the Flask API URL\nflask_api_url = get_flask_proxy_url()","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:01:43.890165Z","iopub.execute_input":"2025-11-30T22:01:43.890509Z","iopub.status.idle":"2025-11-30T22:01:43.899433Z","shell.execute_reply.started":"2025-11-30T22:01:43.89047Z","shell.execute_reply":"2025-11-30T22:01:43.898334Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 7.3: Test Your API\n\nNow you can test your Flask API using cURL, Python requests, or any HTTP client!","metadata":{}},{"cell_type":"code","source":"# Example: Test the API using Python requests\nimport requests\nimport json\nimport threading\n\ndef test_api():\n    # Test health check\n    print(\"Testing health endpoint...\")\n    try:\n        health_response = requests.get(f\"{flask_api_url}/health\")\n        print(f\"Health check: {health_response.json()}\")\n    except Exception as e:\n        print(f\"Note: Run this after getting the URL from the previous cell. Error: {e}\")\n\n    # Test chat endpoint\n    print(\"\\nTesting chat endpoint...\")\n    test_query = {\n        \"query\": \"Find papers on transformer neural networks\",\n        \"session_id\": \"test_session_001\"\n    }\n\n    try:\n        print(\"Sending request (this may take 30-60s)...\")\n        chat_response = requests.post(\n            f\"{flask_api_url}/chat\",\n            headers={\"Content-Type\": \"application/json\"},\n            data=json.dumps(test_query)\n        )\n        print(f\"Chat response: {chat_response.json()}\")\n    except Exception as e:\n        print(f\"Note: Make sure Flask is running. Error: {e}\")\n\n# Run the test in a separate thread to avoid blocking the Main Event Loop\n# (which is needed by the Agent running in the Flask server)\ntest_thread = threading.Thread(target=test_api)\ntest_thread.start()","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:01:49.801461Z","iopub.execute_input":"2025-11-30T22:01:49.802375Z","iopub.status.idle":"2025-11-30T22:01:49.812673Z","shell.execute_reply.started":"2025-11-30T22:01:49.802346Z","shell.execute_reply":"2025-11-30T22:01:49.811609Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 7.4: Using the API from External Tools\n\nYou can also use the API from external tools like Postman, Insomnia, or your own applications.\n\n**Important Security Notes:**\n- ‚ö†Ô∏è **DO NOT SHARE YOUR API URL** - it contains authentication tokens\n- This is for development/testing only\n- For production, deploy to a proper server with authentication\n\nThe Flask API is now ready to receive research queries and return formatted results!","metadata":{}},{"cell_type":"markdown","source":"## üíª 8. Try the ADK Web Interface\n\nADK includes a built-in web interface for interactively chatting with, testing, and debugging your agents.\n\n<img width=\"1200\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/adk-web-ui.gif\" alt=\"ADK Web UI\" />\n\nTo use the ADK web UI, you'll need to create an agent with Python files using the `adk create` command.\n\nRun the command below to generate a `research-agent` folder that contains all the necessary files, including `agent.py` for your code, an `.env` file with your API key pre-configured, and an `__init__.py` file.\n\n### 8.1: Create Research Agent","metadata":{}},{"cell_type":"code","source":"!adk create research-agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:02:08.606018Z","iopub.execute_input":"2025-11-30T22:02:08.606389Z","iopub.status.idle":"2025-11-30T22:02:38.364639Z","shell.execute_reply.started":"2025-11-30T22:02:08.606354Z","shell.execute_reply":"2025-11-30T22:02:38.363448Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n### 8.2: Update Agent Code\n\nThe `adk create` command generates a basic template. We will now overwrite the generated `agent.py` with our complete **Multi-Agent System** code so that the Web UI uses the full functionality we built.","metadata":{}},{"cell_type":"code","source":"# Overwrite the generated agent.py with our Multi-Agent System code\nagent_code = \"\"\"\nimport arxiv\nimport json\nimport os\nimport logging\nfrom typing import List, Any\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.tools import AgentTool\nfrom google.genai import types\n\n# Configure Logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# --- Tools ---\n\ndef search_arxiv(query: str, max_results: int = 5) -> str:\n    \\\"\\\"\\\"Searches ArXiv for research papers matching the query.\\\"\\\"\\\"\n    try:\n        search = arxiv.Search(\n            query=query,\n            max_results=max_results,\n            sort_by=arxiv.SortCriterion.SubmittedDate\n        )\n        \n        results = []\n        for paper in search.results():\n            result = {\n                \"title\": paper.title,\n                \"authors\": [author.name for author in paper.authors],\n                \"summary\": paper.summary[:300] + \"...\" if len(paper.summary) > 300 else paper.summary,\n                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n                \"url\": paper.entry_id,\n            }\n            results.append(result)\n            \n        if not results:\n            return f\"No papers found for query: {query}\"\n\n        formatted = f\"Found {len(results)} papers for '{query}':\\\\n\\\\n\"\n        for i, paper in enumerate(results, 1):\n            authors = \", \".join(paper[\"authors\"][:3])\n            if len(paper[\"authors\"]) > 3:\n                authors += \" et al.\"\n            formatted += f\"{i}. **{paper['title']}**\\\\n\"\n            formatted += f\"   Authors: {authors}\\\\n\"\n            formatted += f\"   Published: {paper['published']}\\\\n\"\n            formatted += f\"   URL: {paper['url']}\\\\n\"\n            formatted += f\"   Summary: {paper['summary']}\\\\n\\\\n\"\n        return formatted\n    except Exception as e:\n        return f\"Error searching ArXiv: {str(e)}\"\n\ndef format_citation(title: str, authors: List[str], year: str, url: str) -> str:\n    \\\"\\\"\\\"Formats a research paper citation.\\\"\\\"\\\"\n    author_str = \", \".join(authors)\n    return f\"{author_str} ({year}). **{title}**. Retrieved from {url}\"\n\n# Use /tmp for writable location in cloud environments\nMEMORY_FILE = \"/tmp/knowledge_base.json\"\n\ndef save_to_memory(key: str, value: Any) -> str:\n    \\\"\\\"\\\"Saves a key-value pair to a persistent JSON file.\\\"\\\"\\\"\n    try:\n        if os.path.exists(MEMORY_FILE):\n            with open(MEMORY_FILE, 'r') as f:\n                data = json.load(f)\n        else:\n            data = {}\n            \n        data[key] = value\n        \n        with open(MEMORY_FILE, 'w') as f:\n            json.dump(data, f, indent=2)\n            \n        return f\"Successfully saved '{key}' to long-term memory.\"\n    except Exception as e:\n        return f\"Error saving to memory: {str(e)}\"\n\n# --- Agents ---\n\nretry_config = types.HttpRetryOptions(\n    attempts=3,\n    exp_base=2,\n    initial_delay=1,\n    http_status_codes=[429, 500, 503],\n)\n\n# Shared Model\nmodel = Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config)\n\n# 1. Researcher Agent\nresearcher_agent = LlmAgent(\n    name=\"researcher_agent\",\n    model=model,\n    description=\"Searches for research papers using ArXiv API.\",\n    instruction='''\n    You are a research assistant with access to ArXiv.\n    When given a research topic:\n    1. Use the 'search_arxiv' tool to find relevant academic papers.\n    2. Focus on recent papers (2023-2025 when possible).\n    3. Return the paper details including titles, authors, dates, and URLs.\n    ''',\n    tools=[search_arxiv]\n)\n\n# 2. Analyst Agent\nanalyst_agent = LlmAgent(\n    name=\"analyst_agent\",\n    model=model,\n    description=\"Analyzes research data and creates visualizations.\",\n    instruction='''\n    You are a data analyst.\n    Given a list of research papers or search results:\n    1. Extract the publication years from the paper information.\n    2. Calculate the distribution of papers by year.\n    3. Create a simple ASCII bar chart showing the distribution.\n    4. Return the analysis summary and the ASCII chart.\n    '''\n)\n\n# 3. Formatter Agent\nformatter_agent = LlmAgent(\n    name=\"formatter_agent\",\n    model=model,\n    description=\"Formats paper details into proper citations.\",\n    instruction='''\n    You are a citation expert. \n    Take the raw paper information and format it into clean academic citations.\n    Use APA format: Authors (Year). Title. Retrieved from URL\n    Return the final list of formatted citations as a numbered list.\n    '''\n)\n\n# 4. Root Agent (Orchestrator)\nroot_agent = LlmAgent(\n    name=\"root_agent\",\n    model=model,\n    instruction='''\n    You are the Lead Research Coordinator.\n    \n    Your workflow is:\n    1. **Research**: Delegate to 'researcher_agent' to find papers on the user's topic.\n    2. **Analyze**: Delegate the findings to 'analyst_agent' to get a distribution of publication years.\n    3. **Format**: Delegate to 'formatter_agent' to get a list of citations.\n    4. **Save**: Use the 'save_to_memory' tool to save the final citation list and analysis to the 'knowledge_base.json' file. Use the topic as the key.\n    5. **Report**: YOU MUST PRINT the final report to the user.\n       - Show the \"Formatted Citations\" list.\n       - Show the \"Publication Year Analysis\" chart.\n       - Confirm that data has been saved to memory.\n       \n    CRITICAL: Do NOT stop after calling tools. You MUST generate a final text response summarizing the results.\n    ''',\n    tools=[\n        AgentTool(agent=researcher_agent), \n        AgentTool(agent=analyst_agent), \n        AgentTool(agent=formatter_agent),\n        save_to_memory\n    ]\n)\n\n# Export the root agent\nagent = root_agent\n\"\"\"\n\nwith open(\"research-agent/agent.py\", \"w\") as f:\n    f.write(agent_code)\n\n# Update requirements.txt to include arxiv\nrequirements = \"\"\"google-adk\narxiv\n\"\"\"\n\nwith open(\"research-agent/requirements.txt\", \"w\") as f:\n    f.write(requirements)\n\nprint(\"‚úÖ Updated 'research-agent/agent.py' with Multi-Agent System code.\")\nprint(\"‚úÖ Updated 'research-agent/requirements.txt' with dependencies.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T22:03:06.417728Z","iopub.execute_input":"2025-11-30T22:03:06.418083Z","iopub.status.idle":"2025-11-30T22:03:06.430241Z","shell.execute_reply.started":"2025-11-30T22:03:06.418054Z","shell.execute_reply":"2025-11-30T22:03:06.42843Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 8.3: Get Your Custom URL\n\nGet your custom URL to access the ADK web UI in the Kaggle Notebooks environment:","metadata":{}},{"cell_type":"code","source":"url_prefix = get_adk_proxy_url()","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:03:13.654948Z","iopub.execute_input":"2025-11-30T22:03:13.655278Z","iopub.status.idle":"2025-11-30T22:03:13.663077Z","shell.execute_reply.started":"2025-11-30T22:03:13.655256Z","shell.execute_reply":"2025-11-30T22:03:13.662082Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 8.4: Run ADK Web\n\nNow we can run ADK web:","metadata":{}},{"cell_type":"code","source":"!adk web --url_prefix {url_prefix}","metadata":{"execution":{"iopub.status.busy":"2025-11-30T22:03:18.013006Z","iopub.execute_input":"2025-11-30T22:03:18.013377Z","iopub.status.idle":"2025-11-30T22:08:29.654577Z","shell.execute_reply.started":"2025-11-30T22:03:18.013351Z","shell.execute_reply":"2025-11-30T22:08:29.653612Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 8.5: Access the UI\n\nNow you can access the ADK web UI using the link above.\n\n‚ÄºÔ∏è **IMPORTANT: DO NOT SHARE THE PROXY LINK** with anyone - treat it as sensitive data as it contains your authentication token in the URL.\n\nOnce you open the link, you'll see the ADK web interface where you can interact with your research agent in a visual interface.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üìã Conclusion\n\nThis project demonstrates a production-ready **Academic Research Assistant Agent** that leverages:\n\n- **ArXiv API Integration**: Direct access to academic papers from ArXiv\n- **Multi-agent architecture**: Specialized agents for research, analysis, and formatting\n- **Custom tools**: ArXiv search, citation formatting, and persistent memory\n- **Session management**: Stateful conversations with context retention\n- **Observability**: Comprehensive logging for debugging and monitoring\n- **Production Deployment**: Ready for deployment to Vertex AI Agent Engine\n- **Scalability**: Cloud-native architecture for handling production workloads\n\n### Next Steps:\n\n1. **Enhance the Agent**: Add more academic databases (PubMed, IEEE, Semantic Scholar)\n2. **Deploy to Production**: Follow Section 6 to deploy on Vertex AI Agent Engine\n3. **Monitor & Improve**: Use Vertex AI's monitoring tools to track performance\n4. **Scale**: Configure auto-scaling based on usage patterns\n\n### Useful Resources:\n\n- [Vertex AI Agent Engine Documentation](https://docs.cloud.google.com/agent-builder/agent-engine/overview)\n- [ArXiv API Guide](https://info.arxiv.org/help/api/index.html)\n- [Google ADK Documentation](https://google.github.io/adk-docs/)\n\nThis agent is now ready for academic researchers to discover, analyze, and cite relevant papers efficiently!","metadata":{}}]}